Automatically generated by Mendeley Desktop 1.19.8
Any changes to this file will be lost if it is regenerated by Mendeley.

BibTeX export options can be customized via Options -> BibTeX in Mendeley Desktop

@article{Chaturvedi2020,
abstract = {Skin Cancer accounts for one-third of all diagnosed cancers worldwide. The prevalence of skin cancers have been rising over the past decades. In recent years, use of dermoscopy has enhanced the diagnostic capability of skin cancer. The accurate diagnosis of skin cancer is challenging for dermatologists as multiple skin cancer types may appear similar in appearance. The dermatologists have an average accuracy of 62% to 80% in skin cancer diagnosis. The research community has been made significant progress in developing automated tools to assist dermatologists in decision making. In this work, we propose an automated computer-aided diagnosis system for multi-class skin (MCS) cancer classification with an exceptionally high accuracy. The proposed method outperformed both expert dermatologists and contemporary deep learning methods for MCS cancer classification. We performed fine-tuning over seven classes of HAM10000 dataset and conducted a comparative study to analyse the performance of five pre-trained convolutional neural networks (CNNs) and four ensemble models. The maximum accuracy of 93.20% for individual model amongst the set of models whereas maximum accuracy of 92.83% for ensemble model is reported in this paper. We propose use of ResNeXt101 for the MCS cancer classification owing to its optimized architecture and ability to gain higher accuracy.},
author = {Chaturvedi, Saket S. and Tembhurne, Jitendra V. and Diwan, Tausif},
doi = {10.1007/s11042-020-09388-2},
file = {:C\:/Users/febri/Desktop/Melanoma/paper/10.1007@s11042-020-09388-2.pdf:pdf},
issn = {15737721},
journal = {Multimedia Tools and Applications},
keywords = {Classification,Deep convolutional neural network,Dermoscopy,Skin Cancer},
number = {39-40},
pages = {28477--28498},
publisher = {Multimedia Tools and Applications},
title = {{A multi-class skin Cancer classification using deep convolutional neural networks}},
volume = {79},
year = {2020}
}
@article{Chaudhari2021,
author = {Chaudhari, Palash},
file = {:C\:/Users/febri/Desktop/Melanoma/paper/30-Article Text-58-1-10-20210903.pdf:pdf},
number = {1},
pages = {47--55},
title = {{Skin Cancer Classification Application Using Machine Learning}},
volume = {2},
year = {2021}
}
@article{Guzel2020,
abstract = {Climate change has become popular in recent years. To discuss and reduce the harmful effects on environment, important actions are taken in international negotiations. Paris Agreement, entered into force in November 2016, aims to limit greenhouse gas (GHG) emissions and maintain the global average temperature raising below 2°C, countries that have ratified the agreement should declare their contribution to reducing GHG emissions. one of the most important components contributing to global GHG emissions is the transportation sector. The GHG emission from the transportation sector is 84.7 Mton CO2eq. which accounts for 16% of the total GHG emissions throughout Turkey in 2017. Road transportation with a rate of 93%, corresponds to the biggest share of GHG emissions from the transportation sector. In the current study, GHG emissions were modelled from 2016 to 2050, in order to assess the impacts of the transportation sector on climate change in Istanbul, which is the most populous city and has the highest number of vehicles in Turkey. Istanbul has a major importance for Turkey, from the point of its energy consumption and climate-related emissions. For this purpose, the Integrated MARKAL-EFOM System (TIMES) as a technology-rich and economic model was used. The results of the study were obtained for the reference scenario, which assumes that the existing plans and policies will continue until 2050. Furthermore, three alternative scenarios were studied which are related to electric rail transportation (Scenario 1), electric and hybrid cars (Scenario 2) and limited CO2 emissions (Scenario 3). Results show that the total GHG reduction is 1.1% Scenario 1, 11% for Scenario 2 and 39% for Scenario 3 in 2050. In the third scenario where the emission limitation was introduced to the model, there was a trend towards vehicles with higher amounts of LPG and CNG to keep the emission at the desired level, and fuel consumption was approximately 5.5% higher than the reference scenario in 2050.},
author = {G{\"{u}}zel, Tuğba Doğan and Alp, Kadir},
doi = {10.1016/j.apr.2020.08.034},
file = {:C\:/Users/febri/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/G{\"{u}}zel, Alp - 2020 - Modeling of greenhouse gas emissions from the transportation sector in Istanbul by 2050.pdf:pdf},
issn = {13091042},
journal = {Atmospheric Pollution Research},
keywords = {Climate change,Emission,Greenhouse gas,Istanbul,TIMES model,Transportation},
number = {12},
pages = {2190--2201},
publisher = {Elsevier B.V.},
title = {{Modeling of greenhouse gas emissions from the transportation sector in Istanbul by 2050}},
url = {https://doi.org/10.1016/j.apr.2020.08.034},
volume = {11},
year = {2020}
}
@book{Deep2021,
author = {Deep, Penerapan and Menggunakan, Learning and Neural, Convolutional and Dengan, Network and Resnet, Arsitektur and Klasifikasi, Untuk and Satria, E K I},
file = {:C\:/Users/febri/Desktop/Melanoma/paper/Tanpa BAB IV dan V (Watermark).pdf:pdf},
isbn = {1165110342},
title = {{Tugas akhir}},
year = {2021}
}
@article{Refianti2019,
abstract = {Melanoma cancer is a type of skin cancer and is the most dangerous one because it causes the most of skin cancer deaths. Melanoma comes from melanocyte cells, melanin-producing cells, so that melanomas are generally brown or black coloured. Melanomas are mostly caused by exposure to ultraviolet radiation that damages the DNA of skin cells. The diagnoses of melanoma cancer are often performed manually by using visuals of the skilled doctors, analyzing the result of dermoscopy examination and match it with medical sciences. Manual detection weakness is highly influenced by human subjectivity that makes it inconsistent in certain conditions. Therefore, a computer assisted technology is needed to help classifying the results of dermoscopy examination and to deduce the results more accurately with a relatively faster time. The making of this application starts with problem analysis, design, implementation, and testing. This application uses deep learning technology with Convolutional Neural Network method and LeNet-5 architecture for classifying image data. The experiment using 44 images data from the training results with a different number of training and epoch resulted the highest percentage of success at 93% in training and 100% in testing, which the number of training data used of 176 images and 100 epochs. This application was created using Python programming language and Keras library as Tensorflow back-end.},
author = {Refianti, Rina and Mutiara, Achmad Benny and Priyandini, Rachmadinna Poetri},
doi = {10.14569/IJACSA.2019.0100353},
file = {:C\:/Users/febri/Desktop/Melanoma/paper/fc6facfe78546fdeb937a9862cafcc32bbce.pdf:pdf},
issn = {21565570},
journal = {International Journal of Advanced Computer Science and Applications},
keywords = {Convolutional neural network,Deep learning,Image classification,LeNet-5,Melanoma skin cancer,Python},
number = {3},
pages = {409--417},
title = {{Classification of melanoma skin cancer using convolutional neural network}},
volume = {10},
year = {2019}
}
@inproceedings{Horzyk2020,
author = {Horzyk, Adrian},
booktitle = {International Joint Conference on Neural Networks (IJCNN)},
doi = {10.1109/IJCNN48605.2020.9206848},
isbn = {9781728169262},
pages = {1--8},
title = {{YOLOv3 Precision Improvement by the Weighted Centers of Confidence Selection}},
year = {2020}
}
@article{Luque2019,
abstract = {A major issue in the classification of class imbalanced datasets involves the determination of the most suitable performance metrics to be used. In previous work using several examples, it has been shown that imbalance can exert a major impact on the value and meaning of accuracy and on certain other well-known performance metrics. In this paper, our approach goes beyond simply studying case studies and develops a systematic analysis of this impact by simulating the results obtained using binary classifiers. A set of functions and numerical indicators are attained which enables the comparison of the behaviour of several performance metrics based on the binary confusion matrix when they are faced with imbalanced datasets. Throughout the paper, a new way to measure the imbalance is defined which surpasses the Imbalance Ratio used in previous studies. From the simulation results, several clusters of performance metrics have been identified that involve the use of Geometric Mean or Bookmaker Informedness as the best null-biased metrics if their focus on classification successes (dismissing the errors) presents no limitation for the specific application where they are used. However, if classification errors must also be considered, then the Matthews Correlation Coefficient arises as the best choice. Finally, a set of null-biased multi-perspective Class Balance Metrics is proposed which extends the concept of Class Balance Accuracy to other performance metrics.},
author = {Luque, Amalia and Carrasco, Alejandro and Mart{\'{i}}n, Alejandro and de las Heras, Ana},
doi = {10.1016/j.patcog.2019.02.023},
file = {:C\:/Users/febri/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Luque et al. - 2019 - The impact of class imbalance in classification performance metrics based on the binary confusion matrix.pdf:pdf},
issn = {00313203},
journal = {Pattern Recognition},
keywords = {Class Balance Metrics,Classification,Imbalanced datasets,Performance measures},
pages = {216--231},
publisher = {Elsevier Ltd},
title = {{The Impact of Class Imbalance in Classification Performance Metrics Based on The Binary Confusion Matrix}},
url = {https://doi.org/10.1016/j.patcog.2019.02.023},
volume = {91},
year = {2019}
}
@article{Yang2021,
abstract = {At present, the main technology of garbage identification and classification is the use of traditional machine vision algorithm or the use of sensors for screening and identification of garbage, in garbage sorting, the first accurate identification and classification of garbage is very necessary. By collecting various types of garbage pictures and building detection data sets, we adopt the garbage identification and detection algorithm based on YOLO-V5 and use data enhancement to improve the robustness of the model, to achieve fast and accurate identification of different types of garbage. Experimental results show that this method has high accuracy, short time consumption, and good robustness.},
author = {Yang, Guanhao and Jin, Jintao and Lei, Qujiang and Wang, Yi and Zhou, Jiangkun and Sun, Zhe and Li, Xiuhao and Wang, Weijun},
doi = {10.1109/ICSIP52628.2021.9688725},
file = {:C\:/Users/febri/Desktop/Melanoma/paper/yang2020.pdf:pdf},
isbn = {9780738133737},
journal = {2021 6th International Conference on Signal and Image Processing, ICSIP 2021},
keywords = {Garbage classification,Garbage identification,Machine vision,YOLOV5},
number = {January 2020},
pages = {11--18},
title = {{Garbage Classification System with YOLOV5 Based on Image Recognition}},
volume = {1},
year = {2021}
}
@article{Mohiyuddin2022,
author = {Mohiyuddin, Aqsa and Basharat, Asma and Ghani, Usman and Peter, Vesel{\'{y}} and Abbas, Sidra and Naeem, Osama Bin and Rizwan, Muhammad},
doi = {https://doi.org/10.1155/2022/1359019},
journal = {Computational and Mathematical Methods in Medicine},
title = {{Social Network-Based Medical Informatics with a Deep Learning Perspective}},
volume = {2022},
year = {2022}
}
@article{Hartanto2021,
author = {Hartanto, Cahyo Adhi and Wibowo, Adi},
file = {:C\:/Users/febri/Desktop/Melanoma/paper/hartanto2020.pdf:pdf},
isbn = {9781728172262},
keywords = {actinic keratosis,another reason,but also able to,faster,images and detect objects,in the captured image,melanoma,mobilenet v2,process,r-cnn,skin cancer,that not only able,to capture images},
pages = {58--63},
title = {{Development of Mobile Skin Cancer Detection using Faster R-CNN and MobileNet v2 Model}},
year = {2021}
}
@article{Ali2021,
author = {Ali, Shahin and Miah, Sipon and Haque, Jahurul and Rahman, Mahbubur},
doi = {10.1016/j.mlwa.2021.100036},
issn = {2666-8270},
journal = {Machine Learning with Applications},
number = {February},
pages = {100036},
publisher = {Elsevier Ltd.},
title = {{Machine Learning with Applications An enhanced technique of skin cancer classification using deep convolutional neural network with transfer learning models}},
volume = {5},
year = {2021}
}
@article{Jivtode2019,
author = {Jivtode, Saudamini S},
doi = {10.21275/ART20198403},
journal = {International Journal of Science and Research (IJSR)},
number = {6},
pages = {144--147},
title = {{Melanoma Skin Cancer Detection by using Segmentation}},
volume = {8},
year = {2019}
}
@article{Nawaz2022a,
author = {Nawaz, Marriam and Naqvi, Rizwan Ali and Saba, Tanzila},
doi = {10.1002/jemt.23908},
file = {:C\:/Users/febri/Desktop/Melanoma/paper/jemt.23908.pdf:pdf},
keywords = {deep learning,faster-rcnn,fuzzy c -means clustering,melanoma,skin cancer},
number = {July 2021},
pages = {339--351},
title = {{Skin cancer detection from dermoscopic images using deep learning and fuzzy k -means clustering}},
year = {2022}
}
@article{Novitasari2020,
abstract = {Whirlwind is a natural disaster that often occurs and is difficult to predict from some time before. Early identification is needed to prevent a lot of casualties and losses. Whirlwind caused by instability in the atmosphere. Instability in the atmosphere usually occurs at the beginning of the day and the whirlwind can be identified based on the upper air parameter which can represent atmospheric instability. The purpose of this research is to optimize SVM classification with SMOTE algorithm to handling problems in imbalanced data and this research can minimize casualties and losses or also be a breakthrough for disaster-prone areas to be given early warning. The process for identifying whirlwind has several stages, namely pre-processing, imbalanced data handling, and classification. Pre-processing is normalized data. Whirlwind data has a classification problem, namely inter-class data that is not balanced so it needs to be corrected using the SMOTE Algorithm. Research on the identification of whirlwind using a combination of SMOTE-SVM produces the best accuracy is 98.8 %. When compared to data without the SMOTE algorithm the results obtained are better if the SMOTE method is applied. The specificity value is also better when given the SMOTE method. Based on these results it can be concluded that SMOTE can overcome the problem of imbalanced data in the upper air data by increasing the value of the classification of the whirlwind.},
author = {Novitasari, D. C.R. and Foeady, A. Z. and Nariswari, R. and Asyhar, A. H. and Ulinnuha, N. and Farida, Y. and Santi, D. R. and Ilham and Setiawan, F.},
doi = {10.1088/1742-6596/1501/1/012010},
file = {:C\:/Users/febri/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Novitasari et al. - 2020 - Whirlwind Classification with Imbalanced Upper Air Data Handling using SMOTE Algorithm and SVM Classifier.pdf:pdf},
issn = {17426596},
journal = {Journal of Physics: Conference Series},
number = {1},
title = {{Whirlwind Classification with Imbalanced Upper Air Data Handling using SMOTE Algorithm and SVM Classifier}},
volume = {1501},
year = {2020}
}
@book{Haq2020,
abstract = {Skin cancer accounts for one-third of all cancer cases and is expected to continue to grow. Skin cancer malignancy, can be resolved by early detection of suspicious skin areas with visual examination. Manual early detection relies heavily on the skills of observers and allows errors to occur, so computational calculations are required to simplify and minimize errors by observers. Early detection of skin cancer using computational calculations is performed by classifying suspicious skin area image data. In this study, the process of learning features and classification of image data was carried out by applying one part of deep learning, namely GoogleNet, which is the architecture of the Convolutional Neural Network (CNN) algorithm introduced by Google in 2014 and was ranked first in the ILSVRC competition with the best performance. . The classification system created produces the accuracy, sensitivity, and specificity values of 100%, 100% and 100%, respectively, with 90% data sharing, 0.4 dropout layer, 8 batch sizes. The results of the system evaluation show that the application of the GoogleNet architecture to the CNN algorithm is an effective way to detect skin cancer based on 014 as an architecture resulting from the classification of image data on suspicious skin areas.},
author = {Haq, Dina Zatusiva},
booktitle = {Universitas Islam Negeri Sunan Ampel Surabaya},
file = {:C\:/Users/febri/Desktop/Melanoma/paper/Dina Zatusiva Haq_H72217050.pdf:pdf},
isbn = {1987012720},
pages = {1--117},
title = {{Klasifikasi Citra Kanker Kulit Menggunakan Convolutional Neural Network Model Googlenet}},
year = {2020}
}
@article{Henriksen2019,
abstract = {Background: Early detection of breast cancer (BC) is crucial in lowering the mortality. Purpose: To present an overview of studies concerning computer-aided detection (CAD) in screening mammography for early detection of BC and compare diagnostic accuracy and recall rates (RR) of single reading (SR) with SR + CAD and double reading (DR) with SR + CAD. Material and Methods: PRISMA guidelines were used as a review protocol. Articles on clinical trials concerning CAD for detection of BC in a screening population were included. The literature search resulted in 1522 records. A total of 1491 records were excluded by abstract and 18 were excluded by full text reading. A total of 13 articles were included. Results: All but two studies from the SR vs. SR + CAD group showed an increased sensitivity and/or cancer detection rate (CDR) when adding CAD. The DR vs. SR + CAD group showed no significant differences in sensitivity and CDR. Adding CAD to SR increased the RR and decreased the specificity in all but one study. For the DR vs. SR + CAD group only one study reported a significant difference in RR. Conclusion: All but two studies showed an increase in RR, sensitivity and CDR when adding CAD to SR. Compared to DR no statistically significant differences in sensitivity or CDR were reported. Additional studies based on organized population-based screening programs, with longer follow-up time, high-volume readers, and digital mammography are needed to evaluate the efficacy of CAD.},
author = {Henriksen, Emilie L. and Carlsen, Jonathan F. and Vejborg, Ilse M.M. and Nielsen, Michael B. and Lauridsen, Carsten A.},
doi = {10.1177/0284185118770917},
file = {::},
issn = {16000455},
journal = {Acta Radiologica},
number = {1},
pages = {13--18},
pmid = {29665706},
title = {{The efficacy of using computer-aided detection (CAD) for detection of breast cancer in mammography screening: a systematic review}},
volume = {60},
year = {2019}
}
@article{Markoulidakis2021,
author = {Markoulidakis, Ioannis and Rallis, Ioannis and Georgoulas, Ioannis and Kopsiaftis, George and Doulamis, Anastasios Doulamis Nikolaos},
doi = {https://doi.org/10.3390/technologies9040081},
file = {:C\:/Users/febri/Desktop/Melanoma/paper/technologies-09-00081-v2.pdf:pdf},
journal = {Technologies},
number = {4},
title = {{Multiclass Confusion Matrix Reduction Method and Its Application on Net Promoter Score Classification Problem}},
volume = {9},
year = {2021}
}
@article{Zhu2021,
abstract = {Object detection on drone-captured scenarios is a recent popular task. As drones always navigate in different altitudes, the object scale varies violently, which burdens the optimization of networks. Moreover, high-speed and low-altitude flight bring in the motion blur on the densely packed objects, which leads to great challenge of object distinction. To solve the two issues mentioned above, we propose TPH-YOLOv5. Based on YOLOv5, we add one more prediction head to detect different-scale objects. Then we replace the original prediction heads with Transformer Prediction Heads (TPH) to explore the prediction potential with self-attention mechanism. We also integrate convolutional block attention model (CBAM) to find attention region on scenarios with dense objects. To achieve more improvement of our proposed TPH-YOLOv5, we provide bags of useful strategies such as data augmentation, multi-scale testing, multi-model integration and utilizing extra classifier. Extensive experiments on dataset VisDrone2021 show that TPH-YOLOv5 have good performance with impressive interpretability on drone-captured scenarios. On DET-test-challenge dataset, the AP result of TPH-YOLOv5 are 39.18%, which is better than previous SOTA method (DPNetV3) by 1.81%. On VisDrone Challenge 2021, TPH-YOLOv5 wins 5th place and achieves well-matched results with 1st place model (AP 39.43%). Compared to baseline model (YOLOv5), TPH-YOLOv5 improves about 7%, which is encouraging and competitive.},
archivePrefix = {arXiv},
arxivId = {2108.11539},
author = {Zhu, Xingkui and Lyu, Shuchang and Wang, Xu and Zhao, Qi},
doi = {10.1109/ICCVW54120.2021.00312},
eprint = {2108.11539},
file = {:C\:/Users/febri/Desktop/Melanoma/paper/Zhu_TPH-YOLOv5_Improved_YOLOv5_Based_on_Transformer_Prediction_Head_for_Object_ICCVW_2021_paper.pdf:pdf},
isbn = {9781665401913},
issn = {15505499},
journal = {Proceedings of the IEEE International Conference on Computer Vision},
pages = {2778--2788},
title = {{TPH-YOLOv5: Improved YOLOv5 Based on Transformer Prediction Head for Object Detection on Drone-captured Scenarios}},
volume = {2021-Octob},
year = {2021}
}
@article{Thanh2020,
abstract = {According to statistics of the American Cancer Society, in 2015, there are about 91,270 American adults diagnosed with melanoma of the skin. For the European Union, there are over 90,000 new cases of melanoma annually. Although melanoma only accounts for about 1% of all skin cancers, it causes most of the skin cancer deaths. Melanoma is considered one of the fastest-growing forms of skin cancer, and hence the early detection is crucial, as early detection is helpful and can provide strong recommendations for specific and suitable treatment regimens. In this work, we propose a method to detect melanoma skin cancer with automatic image processing techniques. Our method includes three stages: pre-process images of skin lesions by adaptive principal curvature, segment skin lesions by the colour normalisation and extract features by the ABCD rule. We provide experimental results of the proposed method on the publicly available International Skin Imaging Collaboration (ISIC) skin lesions dataset. The acquired results on melanoma skin cancer detection indicates that the proposed method has high accuracy, and overall, a good performance: for the segmentation stage, the accuracy, Dice, Jaccard scores are 96.6%, 93.9% and 88.7%, respectively; and for the melanoma detection stage, the accuracy is up to 100% for a selected subset of the ISIC dataset.},
author = {Thanh, Dang N.H. and Prasath, V. B.Surya and Hieu, Le Minh and Hien, Nguyen Ngoc},
doi = {10.1007/s10278-019-00316-x},
file = {:E\:/Skripsi/Previous Articles/Thanh et al. - 2020 - Melanoma Skin Cancer Detection Method Based on Adaptive Principal Curvature, Colour Normalisation and Feature Extr.pdf:pdf},
isbn = {1027801900},
issn = {1618727X},
journal = {Journal of Digital Imaging},
keywords = {ABCD rule,Colour normalisation,Medical image processing,Medical image segmentation,Melanoma,Principal curvatures,Skin Cancer},
number = {3},
pages = {574--585},
pmid = {31848895},
publisher = {Journal of Digital Imaging},
title = {{Melanoma Skin Cancer Detection Method Based on Adaptive Principal Curvature, Colour Normalisation and Feature Extraction with the ABCD Rule}},
volume = {33},
year = {2020}
}
@article{Hussain2021,
author = {Hussain, Nazeer and Mir, Maria and Qian, Lei and Baloch, Mahnoor and Farhan, Muhammad and Khan, Ali and Rehman, Asim-ur- and Erasto, Ebenezeri and Wu, Dong-dong and Ji, Xin-ying},
doi = {10.1016/j.jare.2021.06.014},
issn = {2090-1232},
journal = {Journal of Advanced Research},
number = {xxxx},
publisher = {The Authors},
title = {{Skin cancer biology and barriers to treatment : Recent applications of polymeric micro / nanostructures}},
year = {2021}
}
@article{Attia2019,
abstract = {Background and Objective: Skin melanoma is one of the major health problems in many countries. Dermatologists usually diagnose melanoma by visual inspection of moles. Digital hair removal can provide a non-invasive way to remove hair and hair-like regions as a pre-processing step for skin lesion images. Hair removal has two main steps: hair segmentation and hair gaps inpainting. However, hair segmentation is a challenging task which requires manual tuning of thresholding parameters. Hard-coded threshold leads to over-segmentation (false positives) which in return changes the textural integrity of lesions and or under-segmentation (false negatives) which leaves hair traces and artefacts which affect subsequent diagnosis. Additionally, dermal hair exhibits different characteristics: thin; overlapping; faded; occluded and overlaid on textured lesions. Methods: In this presented paper, we proposed a deep learning approach based on a hybrid network of convolutional and recurrent layers for hair segmentation using weakly labelled data. We utilised the deep encoded features for accurate detection and delineation of hair in skin images. The encoded features are then fed into recurrent neural network layers to encode the spatial dependencies between disjointed patches. Experiments are conducted on a publicly available dataset, called “Towards Melanoma Detection: Challenge”. We chose two metrics to evaluate the produced segmentation masks. The first metric is the Jaccard Index which penalises false positives and false negatives. The second metric is the tumour disturb pattern which assesses the overall effect over the lesion texture due to unnecessary inpainting as a result of over segmentation. The qualitative and quantitative evaluations are employed to compare the proposed technique with state-of-the-art methods. Results: The proposed approach showed superior segmentation accuracy as demonstrated by a Jaccard Index of 77.8% in comparison to a 66.5% reported by the state-of-the-art method. We also achieved tumour disturb pattern as low as 14% compared to 23% for the state-of-the-art method. Conclusion: The hybrid architecture for segmentation was able to accurately delineate and segment the hair from the background including lesions and the skin using weakly labelled ground truth for training.},
author = {Attia, Mohamed and Hossny, Mohammed and Zhou, Hailing and Nahavandi, Saeid and Asadi, Hamed and Yazdabadi, Anousha},
doi = {10.1016/j.cmpb.2019.05.010},
file = {:C\:/Users/febri/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Attia et al. - 2019 - Digital hair segmentation using hybrid convolutional and recurrent neural networks architecture.pdf:pdf},
issn = {18727565},
journal = {Computer Methods and Programs in Biomedicine},
keywords = {Deep learning,Dermatology,Hair detection,Hair segmentation},
pages = {17--30},
pmid = {31319945},
publisher = {Elsevier B.V.},
title = {{Digital Hair Segmentation using Hybrid Convolutional and Recurrent Neural Networks Architecture}},
url = {https://doi.org/10.1016/j.cmpb.2019.05.010},
volume = {177},
year = {2019}
}
@article{Kadampur2020,
author = {Kadampur, Mohammad Ali and Riyaee, Sulaiman Al},
doi = {10.1016/j.imu.2019.100282},
file = {:C\:/Users/febri/Desktop/Melanoma/paper/kadampur-2020.pdf:pdf},
issn = {2352-9148},
journal = {Informatics in Medicine Unlocked},
keywords = {AI,Deep co,Deep learning,Model driven architecture},
number = {December 2019},
pages = {100282},
publisher = {Elsevier Ltd},
title = {{Informatics in Medicine Unlocked Skin cancer detection : Applying a deep learning based model driven architecture in the cloud for classifying dermal cell images}},
url = {https://doi.org/10.1016/j.imu.2019.100282},
volume = {18},
year = {2020}
}
@article{Perez2018,
abstract = {Deep learning models show remarkable results in automated skin lesion analysis. However, these models demand considerable amounts of data, while the availability of annotated skin lesion images is often limited. Data augmentation can expand the training dataset by transforming input images. In this work, we investigate the impact of 13 data augmentation scenarios for melanoma classification trained on three CNNs (Inception-v4, ResNet, and DenseNet). Scenarios include traditional color and geometric transforms, and more unusual augmentations such as elastic transforms, random erasing and a novel augmentation that mixes different lesions. We also explore the use of data augmentation at test-time and the impact of data augmentation on various dataset sizes. Our results confirm the importance of data augmentation in both training and testing and show that it can lead to more performance gains than obtaining new images. The best scenario results in an AUC of 0.882 for melanoma classification without using external data, outperforming the top-ranked submission (0.874) for the ISIC Challenge 2017, which was trained with additional data.},
archivePrefix = {arXiv},
arxivId = {1809.01442},
author = {Perez, F{\'{a}}bio and Vasconcelos, Cristina and Avila, Sandra and Valle, Eduardo},
doi = {10.1007/978-3-030-01201-4_33},
eprint = {1809.01442},
file = {:C\:/Users/febri/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Perez et al. - 2018 - Data augmentation for skin lesion analysis.pdf:pdf},
isbn = {9783030012007},
issn = {16113349},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
keywords = {Data augmentation,Deep learning,Skin lesion analysis},
pages = {303--311},
title = {{Data Augmentation for Skin Lesion Analysis}},
volume = {11041 LNCS},
year = {2018}
}
@inproceedings{Fuadah2020,
abstract = {Skin cancer is a type of cancer that grows in the skin tissue, which can cause damage to the surrounding tissue, disability, and even death. In Indonesia, skin cancer is the third leading for most cancer cases after cervical and breast cancer. The accuracy of diagnosis and the early proper treatment can minimize and control the harmful effects of skin cancer. Due to the similar shape of the lesion between skin cancer and benign tumor lesions, physicians consuming much more time in diagnosing these lesions. The system was developed in this study could identify skin cancer and benign tumor lesions automatically using the Convolutional Neural Network (CNN). The proposed model consists of three hidden layers with an output channel of 16,32, and 64 for each layer respectively. The proposed model uses several optimizers such as SGD, RMSprop, Adam, and Nadam with a learning rate of 0.001. Adam optimizer provides the best performance with an accuracy value of 99% in identifying the skin lesions from the ISIC dataset into 4 classes, namely dermatofibroma, nevus pigmentosus, squamous cell carcinoma, and melanoma. The results obtained outperform the performance of the existing skin cancer classification system.},
author = {Fu'adah, Yunendah Nur and Pratiwi, Nk Caecar and Pramudito, Muhammad Adnan and Ibrahim, Nur},
booktitle = {IOP Conference Series: Materials Science and Engineering},
doi = {10.1088/1757-899X/982/1/012005},
file = {:E\:/Skripsi/Previous Articles//Fu'adah et al. - 2020 - Convolutional Neural Network (CNN) for Automatic Skin Cancer Classification System.pdf:pdf},
issn = {1757899X},
month = {dec},
number = {1},
publisher = {IOP Publishing Ltd},
title = {{Convolutional Neural Network (CNN) for Automatic Skin Cancer Classification System}},
volume = {982},
year = {2020}
}
@article{Kim2022,
author = {Kim, Jun-hwa and Kim, Namho and Park, Yong Woon},
file = {:C\:/Users/febri/Desktop/Melanoma/paper/jmse-10-00377-v2.pdf:pdf},
keywords = {-h,c,citation,classification based on yolo-v5,data relabel,deep learning,j,kim,maritime dataset,n,object detection,object detection and,park,s,w,won,y},
title = {{Object Detection and Classification Based on YOLO-V5 with Improved Maritime Dataset}},
year = {2022}
}
@article{Alquran2017,
abstract = {Melanoma skin cancer detection at an early stage is crucial for an efficient treatment. Recently, it is well known that, the most dangerous form of skin cancer among the other types of skin cancer is melanoma because it's much more likely to spread to other parts of the body if not diagnosed and treated early. The non-invasive medical computer vision or medical image processing plays increasingly significant role in clinical diagnosis of different diseases. Such techniques provide an automatic image analysis tool for an accurate and fast evaluation of the lesion. The steps involved in this study are collecting dermoscopy image database, preprocessing, segmentation using thresholding, statistical feature extraction using Gray Level Co-occurrence Matrix (GLCM), Asymmetry, Border, Color, Diameter, (ABCD) etc., feature selection using Principal component analysis (PCA), calculating total Dermoscopy Score and then classification using Support Vector Machine (SVM). The results show that the achieved classification accuracy is 92.1%.},
author = {Alquran, Hiam and Qasmieh, Isam Abu and Alqudah, Ali Mohammad and Alhammouri, Sajidah and Alawneh, Esraa and Abughazaleh, Ammar and Hasayen, Firas},
doi = {10.1109/AEECT.2017.8257738},
file = {:C\:/Users/febri/Desktop/Melanoma/paper/alquran2017.pdf:pdf},
isbn = {9781509059690},
journal = {2017 IEEE Jordan Conference on Applied Electrical Engineering and Computing Technologies, AEECT 2017},
keywords = {Features,Image processing,Melanoma skin cancer,Principal component analysis,Support vector machine},
pages = {1--5},
title = {{The Melanoma Skin Cancer Detection and Classification using Support Vector Machine}},
year = {2017}
}
@article{Jiang2021,
abstract = {Object detection techniques are the foundation for the artificial intelligence field. This research paper gives a brief overview of the You Only Look Once (YOLO) algorithm and its subsequent advanced versions. Through the analysis, we reach many remarks and insightful results. The results show the differences and similarities among the YOLO versions and between YOLO and Convolutional Neural Networks (CNNs). The central insight is the YOLO algorithm improvement is still ongoing.This article briefly describes the development process of the YOLO algorithm, summarizes the methods of target recognition and feature selection, and provides literature support for the targeted picture news and feature extraction in the financial and other fields. Besides, this paper contributes a lot to YOLO and other object detection literature.},
author = {Jiang, Peiyuan and Ergu, Daji and Liu, Fangyao and Cai, Ying and Ma, Bo},
doi = {10.1016/j.procs.2022.01.135},
issn = {18770509},
journal = {Procedia Computer Science},
pages = {1066--1073},
title = {{A Review of Yolo Algorithm Developments}},
volume = {199},
year = {2021}
}
@article{Tegunov2019,
abstract = {The acquisition of cryo-electron microscopy (cryo-EM) data from biological specimens must be tightly coupled to data preprocessing to ensure the best data quality and microscope usage. Here we describe Warp, a software that automates all preprocessing steps of cryo-EM data acquisition and enables real-time evaluation. Warp corrects micrographs for global and local motion, estimates the local defocus and monitors key parameters for each recorded micrograph or tomographic tilt series in real time. The software further includes deep-learning-based models for accurate particle picking and image denoising. The output from Warp can be fed into established programs for particle classification and 3D-map refinement. Our benchmarks show improvement in the nominal resolution, which went from 3.9 {\AA} to 3.2 {\AA}, of a published cryo-EM data set for influenza virus hemagglutinin. Warp is easy to install from http://github.com/cramerlab/warp and computationally inexpensive, and has an intuitive, streamlined user interface.},
author = {Tegunov, Dimitry and Cramer, Patrick},
doi = {10.1038/s41592-019-0580-y},
file = {:C\:/Users/febri/Desktop/Melanoma/paper/Tegunov Dkk 2019.pdf:pdf},
issn = {15487105},
journal = {Nature Methods},
number = {11},
pages = {1146--1152},
pmid = {31591575},
publisher = {Springer US},
title = {{Real-time cryo-electron microscopy data preprocessing with Warp}},
url = {http://dx.doi.org/10.1038/s41592-019-0580-y},
volume = {16},
year = {2019}
}
@article{Xu2021,
author = {Xu, Qingqing and Zhu, Zhiyu and Ge, Huilin and Zhang, Zheqing and Zang, Xu},
file = {:C\:/Users/febri/Desktop/Melanoma/paper/Effective_Face_Detector_Based_on_YOLOv5_and_Superr.pdf:pdf},
title = {{Effective Face Detector Based on YOLOv5 and Superresolution Reconstruction}},
volume = {2021},
year = {2021}
}
@article{Victor2017,
abstract = {Cancer is a deadly disease in today's world. Various types of cancers are spreading for which skin cancer becomes a very common cancer nowadays. Skin cancer can be of two types namely melanoma and non melanoma cancer. The objective of this paper is to detect and classify the benign and the normal image. Benign meaning the normal image, melanoma the cancerous one. And more over compare the various classification algorithms. Detection of skin cancer in earlier stages can be a life saving process. The detection of skin cancer includes four important stages namely Pre-processing, Segmentation, Feature Extraction and Classification. Detection can help in curing the cancer and hence detection plays a very vital role. In this paper, pre-processing the first and the foremost part of image processing which helps in noise removal is done by means of the median filter where the output of the median filter which is fed as an input to the histogram equalization phase of the pre-processing stage, then the input of the histogram equalized image is fed as an input to the segmentation phase where Otsu's thresholding is done to separate the foreground and the background. The segmentation helps to identify the region of interest, Now using the area, mean, variance and standard deviation of the extracted output from the segmentation phase the calculations for feature extraction is carried and the output is fed into classifiers like Support Vector Machine (SVM), K- Nearest Neighbor (KNN), Decision tree(DT) and Boosted Tree(BT).Comparison of the classification is done. The algorithm shows the accuracy of the classification rate of KNN is 92.70%, SVM is 93.70%, Decision tree (DT) is 89.5% and finally the boosted tree (BT) is 84.30%.},
author = {Victor, Akila and Ghalib, Muhammad Rukunuddin},
doi = {10.22266/ijies2017.0630.50},
file = {:C\:/Users/febri/Desktop/Melanoma/paper/Victor Ghalib 2017.pdf:pdf},
issn = {21853118},
journal = {International Journal of Intelligent Engineering and Systems},
keywords = {Boosted Tree,Decision Tree,KNN,SVM},
number = {3},
pages = {444--451},
title = {{Automatic Detection and Classification of Skin Cancer}},
volume = {10},
year = {2017}
}
@article{Shorfuzzaman2021,
author = {Shorfuzzaman, Mohammad},
doi = {10.1007/s00530-021-00787-5},
file = {:E\:/Skripsi/Previous Articles/Shorfuzzaman 2021.pdf:pdf},
isbn = {0123456789},
issn = {1432-1882},
journal = {Multimedia Systems},
keywords = {Explai,Melanoma,Skin cancer,Stacked ensemble model,dermoscopic images,explainable deep learning,melanoma,skin cancer,stacked ensemble model},
number = {0123456789},
publisher = {Springer Berlin Heidelberg},
title = {{An explainable stacked ensemble of deep learning models for improved melanoma skin cancer detection}},
url = {https://doi.org/10.1007/s00530-021-00787-5},
year = {2021}
}
@article{Matematika2022,
author = {Matematika, Program Studi and Sains, Fakultas and Teknologi, D A N and Islam, Universitas and Sunan, Negeri},
file = {:C\:/Users/febri/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Matematika et al. - 2022 - Klasifikasi kanker kulit pada citra dermoscopy menggunakan gray level co-occurrence matrix (glcm) dan kernel.pdf:pdf},
title = {{Klasifikasi kanker kulit pada citra dermoscopy menggunakan gray level co-occurrence matrix (glcm) dan kernel extreme learning machine (kelm)}},
year = {2022}
}
@article{Loey2021,
abstract = {Deep learning has shown tremendous potential in many real-life applications in different domains. One of these potentials is object detection. Recent object detection which is based on deep learning models has achieved promising results concerning the finding of an object in images. The objective of this paper is to annotate and localize the medical face mask objects in real-life images. Wearing a medical face mask in public areas, protect people from COVID-19 transmission among them. The proposed model consists of two components. The first component is designed for the feature extraction process based on the ResNet-50 deep transfer learning model. While the second component is designed for the detection of medical face masks based on YOLO v2. Two medical face masks datasets have been combined in one dataset to be investigated through this research. To improve the object detection process, mean IoU has been used to estimate the best number of anchor boxes. The achieved results concluded that the adam optimizer achieved the highest average precision percentage of 81% as a detector. Finally, a comparative result with related work has been presented at the end of the research. The proposed detector achieved higher accuracy and precision than the related work.},
author = {Loey, Mohamed and Manogaran, Gunasekaran and Taha, Mohamed Hamed N. and Khalifa, Nour Eldeen M.},
doi = {10.1016/j.scs.2020.102600},
file = {:C\:/Users/febri/Desktop/Melanoma/paper/10.1016@j.scs.2020.102600.pdf:pdf},
issn = {22106707},
journal = {Sustainable Cities and Society},
keywords = {COVID-19,Deep learning,Medical masked face,ResNet,YOLO},
pages = {102600},
pmid = {33200063},
publisher = {Elsevier B.V.},
title = {{Fighting against COVID-19: A novel deep learning model based on YOLO-v2 with ResNet-50 for medical face mask detection}},
url = {https://doi.org/10.1016/j.scs.2020.102600},
volume = {65},
year = {2021}
}
@article{Fang2021,
abstract = {Diversity and unpredictability of artifacts potentially presented to an iris sensor calls for presentation attack detection methods that are agnostic to specificity of presentation attack instruments. This article proposes a method that combines two-dimensional and three-dimensional properties of the observed iris to address the problem of spoof detection in case when some properties of artifacts are unknown. The 2D (textural) iris features are extracted by a state-of-the-art method employing Binary Statistical Image Features (BSIF) and an ensemble of classifiers is used to deliver 2D modality-related decision. The 3D (shape) iris features are reconstructed by a photometric stereo method from only two images captured under near-infrared illumination placed at two different angles, as in many current commercial iris recognition sensors. The map of normal vectors is used to assess the convexity of the observed iris surface. The combination of these two approaches has been applied to detect whether a subject is wearing a textured contact lens to disguise their identity. Extensive experiments with NDCLD'15 dataset, and a newly collected NDIris3D dataset show that the proposed method is highly robust under various open-set testing scenarios, and that it outperforms all available open-source iris PAD methods tested in identical scenarios. The source code and the newly prepared benchmark are made available along with this article.},
archivePrefix = {arXiv},
arxivId = {2002.09137},
author = {Fang, Zhaoyuan and Czajka, Adam and Bowyer, Kevin W.},
doi = {10.1109/TIFS.2020.3015547},
eprint = {2002.09137},
file = {:C\:/Users/febri/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Fang, Czajka, Bowyer - 2021 - Robust iris presentation attack detection fusing 2D and 3D information(3).pdf:pdf},
issn = {15566021},
journal = {IEEE Transactions on Information Forensics and Security},
keywords = {Iris recognition,information fusion,presentation attack detection,shape features,texture features},
pages = {510--520},
title = {{Robust iris presentation attack detection fusing 2D and 3D information}},
volume = {16},
year = {2021}
}
@article{Putra2020,
abstract = {In recent years, deep learning has taken the spotlight in automated medical bioimaging. However, the performance of current state-of-the-art score stems primarily from well-tuned parameters and architecture. There is still only limited research focused on dynamic data augmentation, even in the fields of machine learning and computer vision. In this study, we propose a dynamic training and testing augmentation capable of increasing performance significantly. The searching augmentation framework used in this study requires fewer GPU hours than a conventional search algorithm, which needs to train a new model every time augmentation is proposed. Speeding up of the search algorithm is achieved by using Bayesian optimization on a trained model, so we do not have to train a new model every time a new augmentation policy is proposed. The performance of our method is compared with that of a single model and the ensemble model that happens to be the winner of the ISIC 2019 challenge. Furthermore, we use the latest compact yet significantly accurate network architecture EfficientNet as the backbone system. Our method delivers a superior result, and this study also shares the searched augmentation policy utilized, which requires extraordinary resources. Thus, other researchers can use the searched augmentation policies for dermoscopic images to improve performance.},
author = {Putra, Tryan Aditya and Rufaida, Syahidah Izza and Leu, Jenq Shiou},
doi = {10.1109/ACCESS.2020.2976045},
file = {:C\:/Users/febri/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Putra, Rufaida, Leu - 2020 - Enhanced Skin Condition Prediction through Machine Learning Using Dynamic Training and Testing Augmentation.pdf:pdf},
issn = {21693536},
journal = {IEEE Access},
keywords = {Augmentation,Dermoscopic images,Machine learning,Skin cancer},
pages = {40536--40546},
publisher = {IEEE},
title = {{Enhanced Skin Condition Prediction through Machine Learning Using Dynamic Training and Testing Augmentation}},
volume = {8},
year = {2020}
}
@article{Jinnai2020,
abstract = {Recent studies have demonstrated the usefulness of convolutional neural networks (CNNs) to classify images of melanoma, with accuracies comparable to those achieved by dermatologists. However, the performance of a CNN trained with only clinical images of a pigmented skin lesion in a clinical image classification task, in competition with dermatologists, has not been reported to date. In this study, we extracted 5846 clinical images of pigmented skin lesions from 3551 patients. Pigmented skin lesions included malignant tumors (malignant melanoma and basal cell carcinoma) and benign tumors (nevus, seborrhoeic keratosis, senile lentigo, and hematoma/hemangioma). We created the test dataset by randomly selecting 666 patients out of them and picking one image per patient, and created the training dataset by giving bounding-box annotations to the rest of the images (4732 images, 2885 patients). Subsequently, we trained a faster, region-based CNN (FRCNN) with the training dataset and checked the performance of the model on the test dataset. In addition, ten board-certified dermatologists (BCDs) and ten dermatologic trainees (TRNs) took the same tests, and we compared their diagnostic accuracy with FRCNN. For six-class classification, the accuracy of FRCNN was 86.2%, and that of the BCDs and TRNs was 79.5% (p = 0.0081) and 75.1% (p < 0.00001), respectively. For two-class classification (benign or malignant), the accuracy, sensitivity, and specificity were 91.5%, 83.3%, and 94.5% by FRCNN; 86.6%, 86.3%, and 86.6% by BCD; and 85.3%, 83.5%, and 85.9% by TRN, respectively. False positive rates and positive predictive values were 5.5% and 84.7% by FRCNN, 13.4% and 70.5% by BCD, and 14.1% and 68.5% by TRN, respectively. We compared the classification performance of FRCNN with 20 dermatologists. As a result, the classification accuracy of FRCNN was better than that of the dermatologists. In the future, we plan to implement this system in society and have it used by the general public, in order to improve the prognosis of skin cancer.},
author = {Jinnai, Shunichi and Yamazaki, Naoya and Hirano, Yuichiro and Sugawara, Yohei and Ohe, Yuichiro and Hamamoto, Ryuji},
doi = {10.3390/biom10081123},
file = {:C\:/Users/febri/Desktop/Melanoma/paper/Jinnai Yamazaki Dkk 2020.pdf:pdf},
issn = {2218273X},
journal = {Biomolecules},
keywords = {Artificial intelligence (AI),Deep learning,Melanoma,Neural network,Skin cancer},
number = {8},
pages = {1--13},
pmid = {32751349},
title = {{The development of a skin cancer classification system for pigmented skin lesions using deep learning}},
volume = {10},
year = {2020}
}
@article{Hasan2022,
abstract = {Background and Objective: Although automated Skin Lesion Classification (SLC) is a crucial integral step in computer-aided diagnosis, it remains challenging due to variability in textures, colors, indistinguishable boundaries, and shapes. Methods: This article proposes an automated dermoscopic SLC framework named Dermoscopic Expert (DermoExpert). It combines the pre-processing and hybrid Convolutional Neural Network (hybrid-CNN). The proposed hybrid-CNN has three distinct feature extractor modules, which are fused to achieve better-depth feature maps of the lesion. Those single and fused feature maps are classified using different fully connected layers, then ensembled to predict a lesion class. In the proposed pre-processing, we apply lesion segmentation, augmentation (geometry- and intensity-based), and class rebalancing (penalizing the majority class's loss and merging additional images to the minority classes). Moreover, we leverage transfer learning from the pre-trained models. Finally, we deploy the weights of our DermoExpert to a possible web application. Results: We evaluate our DermoExpert on the ISIC-2016, ISIC-2017, and ISIC-2018 datasets, where the DermoExpert has achieved the area under the receiver operating characteristic curve (AUC) of 0.96, 0.95, and 0.97, respectively. The experimental results improve the state-of-the-art by the margins of 10.0% and 2.0%, respectively, for the ISIC-2016 and ISIC-2017 datasets in terms of AUC. The DermoExpert also outperforms by 3.0% for the ISIC-2018 dataset concerning a balanced accuracy. Conclusion: Since DermoExpert provides better classification outcomes on three different datasets, leading to a better recognition tool to assist dermatologists. Our source code and segmented masks for the ISIC-2018 dataset will be available as a public benchmark for future improvements.},
author = {Hasan, Md Kamrul and Elahi, Md Toufick E. and Alam, Md Ashraful and Jawad, Md Tasnim and Mart{\'{i}}, Robert},
doi = {10.1016/j.imu.2021.100819},
file = {:C\:/Users/febri/Desktop/Melanoma/paper/2021.02.02.21251038v2.full.pdf:pdf},
issn = {23529148},
journal = {Informatics in Medicine Unlocked},
keywords = {Convolutional neural networks,ISIC skin lesion datasets,Image augmentation,Skin lesion classification and segmentation,Transfer learning},
pages = {1--45},
title = {{DermoExpert: Skin lesion classification using a hybrid convolutional neural network through segmentation, transfer learning, and augmentation}},
volume = {28},
year = {2022}
}
@article{Qiu2022,
author = {Qiu, Zhi and Zhao, Zuoxi and Chen, Shaoji and Zeng, Junyuan and Huang, Yuan and Xiang, Borui},
doi = {https://doi.org/10.3390/rs14081895},
journal = {Remote Sensing},
number = {8},
pages = {1895},
title = {{Application of an Improved YOLOv5 Algorithm in Real-Time Detection of Foreign Objects by Ground Penetrating Radar}},
volume = {14},
year = {2022}
}
@phdthesis{Kretzler2013,
author = {Kretzler, Madison Elizabeth},
file = {:C\:/Users/febri/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Kretzler - 2013 - AUTOMATED CURVED HAIR DETECTION AND REMOVAL IN SKIN IMAGES TO SUPPORT AUTOMATED MELANOMA DETECTION.pdf:pdf},
title = {{Automated Curved Hair Detection and Removal in Skin Images to Support Automated Melanoma Detection}},
url = {http://rave.ohiolink.edu/etdc/view?acc_num=case1365125074},
year = {2013}
}
@article{Mohd2017,
abstract = {— Detection of skin cancer gives the best chance of being diagnosed early. Biopsy method for skin cancer detection is much painful. Human interpretation contains difficulty and subjectivity therefore automated analysis of skin cancer affected images has become important. This paper proposes an automatic medical image classification method to classify two major type skin cancers: Melanoma, and Non-melanoma. In this paper, we have used the color and texture features in combination which gives better results than using color or gray level information alone. We have used k-means clustering algorithm to segment the lesion. The features are extracted by six different color-texture feature extractors from the segmented images. Classification accuracy of our proposed system is evaluated on four different types of classifiers and their values are compared with one another. The results of the proposed system are computed on five different classification rate in order to perform better analysis of our proposed system.},
author = {Mohd, A and Ram, G K and Shafeeq, A},
file = {:C\:/Users/febri/Desktop/Melanoma/paper/Anas Gupta Dkk 2017.pdf:pdf},
journal = {Int J Tech Res Appl},
keywords = {K-means clustering,local binary pattern and color percentile,segmentation},
number = {1},
pages = {62--65},
title = {{Skin Cancer Classification Using K-Means Clustering}},
url = {www.ijtra.com},
volume = {5},
year = {2017}
}
@article{ONeill2019,
abstract = {Current recommendations by the United States Preventive Services Task Force do not support screening for skin cancer. Melanoma is unique among cancers because detection is through visual inspection. Development of technologies that aid visual inspection have supported screening strategies in high-risk populations such as older fair skinned males with personal or family history of melanoma. Clearly delineating these populations and appropriate utilization of these newer technologies will be imperative in future screening paradigms.},
author = {O'Neill, Conor H. and Scoggins, Charles R.},
doi = {10.1002/jso.25604},
file = {:C\:/Users/febri/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/O'Neill, Scoggins - 2019 - Melanoma.pdf:pdf},
issn = {10969098},
journal = {Journal of Surgical Oncology},
keywords = {melanoma,screening,skin cancer},
number = {5},
pages = {873--881},
pmid = {31246291},
publisher = {John Wiley & Sons, Ltd},
title = {{Melanoma}},
url = {http://dx.doi.org/10.1002/jso.25604},
volume = {120},
year = {2019}
}
@article{V2019,
author = {V, Dick and C, Sinz and M, Mittlb{\"{o}}ck and H, Kittler and P., Tschandl},
doi = {10.1001/jamadermatol.2019.1375},
journal = {JAMA Dermatol},
number = {11},
pages = {1291--1299},
title = {{Accuracy of Computer-Aided Diagnosis of Melanoma: A Meta-analysis}},
volume = {155},
year = {2019}
}
@article{Huang2020,
author = {Huang, Yi-qi and Zheng, Jia-chun and Sun, Shi-dan and Yang, Cheng-fu and Liu, Jing},
doi = {https://doi.org/10.3390/app10093079},
journal = {Applied Sciences},
title = {{Optimized YOLOv3 Algorithm and Its Application in Traffic Flow Detections}},
year = {2020}
}
@article{Waldman2019,
author = {Waldman, Reid A. and Grant-Kels, Jane M.},
doi = {10.1016/j.jaad.2018.06.069},
file = {:C\:/Users/febri/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Waldman, Grant-Kels - 2019 - The role of sunscreen in the prevention of cutaneous melanoma and nonmelanoma skin cancer.pdf:pdf},
issn = {10976787},
journal = {Journal of the American Academy of Dermatology},
number = {2},
pages = {574--576.e1},
pmid = {30012373},
publisher = {American Academy of Dermatology, Inc.},
title = {{The Role of Sunscreen in The Prevention of Cutaneous Melanoma and Nonmelanoma Skin Cancer}},
url = {https://doi.org/10.1016/j.jaad.2018.06.069},
volume = {80},
year = {2019}
}
@article{Wang2018,
abstract = {An increasing need of running Convolutional Neural Network (CNN) models on mobile devices with limited computing power and memory resource encourages studies on efficient model design. A number of efficient architectures have been proposed in recent years, for example, MobileNet, ShuffleNet, and NASNet-A. However, all these models are heavily dependent on depthwise separable convolution which lacks efficient implementation in most deep learning frameworks. In this study, we propose an efficient architecture named PeleeNet, which is built with conventional convolution instead. On ImageNet ILSVRC 2012 dataset, our proposed PeleeNet achieves a higher accuracy by 0.6% (71.3% vs. 70.7%) and 11% lower computational cost than MobileNet, the state-of-the-art efficient architecture. Meanwhile, PeleeNet is only half of the model size of MobileNet. We then propose a real-time object detection system by combining PeleeNet with Single Shot MultiBox Detector (SSD) method and optimizing the architecture for fast speed. Our proposed detection system1, named Pelee, achieves 70.9% mAP (mean average precision) on PASCAL VOC2007 dataset at the speed of 17.1 FPS on iPhone 6s and 23.6 FPS on iPhone 8. Compared to TinyYOLOv2, our proposed Pelee is more accurate (70.9% vs. 57.1%), 1.88 times lower in computational cost and 1.92 times smaller in model size.},
author = {Wang, Robert J. and Li, Xiang and Ao, Shuang and Ling, Charles X.},
file = {:C\:/Users/febri/Desktop/Melanoma/paper/Wang Li 2018.pdf:pdf},
journal = {6th International Conference on Learning Representations, ICLR 2018 - Workshop Track Proceedings},
number = {NeurIPS},
pages = {1--10},
title = {{Pelee: A Real-Time Object Detection System on Mobile Devices}},
year = {2018}
}
@article{Al-masni2020,
author = {Al-masni, Mohammed A and Kim, Woo-ram and Kim, Eung Yeop and Noh, Young and Kim, Dong-hyun},
file = {:C\:/Users/febri/Desktop/Melanoma/paper/al-masni2020.pdf:pdf},
isbn = {9781728119908},
pages = {1055--1058},
title = {{A Two Cascaded Network Integrating Regional – based YOLO and 3D-CNN for Cerebral Microbleeds Detection}},
year = {2020}
}
@article{Jin2020,
author = {Jin, Yuanzhe},
file = {:C\:/Users/febri/Desktop/Melanoma/paper/10.1109@ICECCE49384.2020.9179384.pdf:pdf},
number = {June},
pages = {1--5},
title = {{Embedded Real-Time Pedestrian Detection System Using YOLO Optimized by LNN}},
year = {2020}
}
@article{Laikova2019,
abstract = {Skin cancer has always been and remains the leader among all tumors in terms of occurrence. One of the main factors responsible for skin cancer, natural and artificial UV radiation, causes the mutations that transform healthy cells into cancer cells. These mutations inactivate apoptosis, an event required to avoid the malignant transformation of healthy cells. Among these deadliest of cancers, melanoma and its ‘younger sister', Merkel cell carcinoma, are the most lethal. The heavy toll of skin cancers stems from their rapid progression and the fact that they metastasize easily. Added to this is the difficulty in determining reliable margins when excising tumors and the lack of effective chemotherapy. Possibly the biggest problem posed by skin cancer is reliably detecting the extent to which cancer cells have spread throughout the body. The initial tumor is visible and can be removed, whereas metastases are invisible to the naked eye and much harder to eliminate. In our opinion, antisense oligonucleotides, which can be used in the form of targeted ointments, provide real hope as a treatment that will eliminate cancer cells near the tumor focus both before and after surgery.},
author = {Laikova, Kateryna V. and Oberemok, Volodymyr V. and Krasnodubets, Alisa M. and Gal'chinsky, Nikita V. and Useinov, Refat Z. and Novikov, Ilya A. and Temirova, Zenure Z. and Gorlov, Mikhail V. and Shved, Nikita A. and Kumeiko, Vadim V. and Makalish, Tatiana P. and Bessalova, Evgeniya Y. and Fomochkina, Iryna I. and Esin, Andrey S. and Volkov, Mikhail E. and Kubyshkin, Anatoly V.},
doi = {10.3390/molecules24081516},
file = {:C\:/Users/febri/Desktop/Melanoma/paper/Laikova Oberemok Dkk 2019.pdf:pdf},
issn = {14203049},
journal = {Molecules},
keywords = {Antisense oligonucleotides,Basal cell carcinoma,Dermatofibrosarcoma protuberans,Melanoma,Merkel cell carcinoma,Mutations,Skin,Squamous cell carcinoma,Ultraviolet radiation},
number = {8},
pmid = {30999681},
title = {{Advances in the understanding of skin cancer: Ultraviolet radiation, mutations, and antisense oligonucleotides as anticancer drugs}},
volume = {24},
year = {2019}
}
@article{Chen2021,
author = {Chen, How Yong and Fakhri, Ahmad and Nasir, Ab and Muhammad, Khairul Fikri and Majeed, Anwar P P Abdul and Azraai, Mohd and Razman, Mohd and Zakaria, Muhammad Aizzat},
file = {:C\:/Users/febri/Desktop/Melanoma/paper/27676.pdf:pdf},
number = {2},
pages = {25--30},
title = {{Glove Defect Detection Via YOLO V5}},
volume = {3},
year = {2021}
}
@article{Hosny2018,
author = {Hosny, Khalid M and Kassem, Mohamed A and Foaud, Mohamed M},
file = {:C\:/Users/febri/Desktop/Melanoma/paper/Hosny Kassem Dkk 2018.pdf:pdf},
isbn = {9781538681541},
journal = {2018 9th Cairo International Biomedical Engineering Conference (CIBEC)},
pages = {90--93},
publisher = {IEEE},
title = {{Skin Cancer Classification using Deep Learning and Transfer Learning}},
year = {2018}
}
@article{Adla2021,
author = {Adla, Devakishan and Rami, G Venkata and Padmalaya, Reddy and Karuna, Nayak G},
doi = {10.1007/s10619-021-07360-z},
file = {:C\:/Users/febri/Desktop/Melanoma/paper/adla2021.pdf:pdf},
isbn = {0123456789},
issn = {1573-7578},
journal = {Distributed and Parallel Databases},
keywords = {Skin lesion,Dermoscopic images,Image classificatio,capsule networks,deep learning,dermoscopic images,hair removal,image classification,image segmentation,isic dataset,skin lesion},
number = {0123456789},
publisher = {Springer US},
title = {{Deep learning ‑ based computer aided diagnosis model for skin cancer detection and classification}},
url = {https://doi.org/10.1007/s10619-021-07360-z},
year = {2021}
}
@inproceedings{Nur2020,
author = {Nur, Yunendah and Pratiwi, N K Caecar and Pramudito, Muhammad Adnan},
booktitle = {IOP Conference Series: Materials Science and Engineering},
doi = {10.1088/1757-899X/982/1/012005},
title = {{Convolutional Neural Network ( CNN ) for Automatic Skin Cancer Classification System}},
year = {2020}
}
@article{Saherish2020,
author = {Saherish, Farkhanda and Megha, J V},
file = {:C\:/Users/febri/AppData/Local/Mendeley Ltd/Mendeley Desktop/Downloaded//Saherish, Megha - 2020 - A Survey on Melanoma Skin Cancer Detection using CNN.pdf:pdf},
keywords = {clas-sification,convolutional neural networks,feature extraction,machine learning,pre-processing,segmentation},
pages = {1--4},
title = {{A Survey on Melanoma Skin Cancer Detection using CNN}},
year = {2020}
}
@article{Redmon2016,
abstract = {We present YOLO, a new approach to object detection. Prior work on object detection repurposes classifiers to perform detection. Instead, we frame object detection as a regression problem to spatially separated bounding boxes and associated class probabilities. A single neural network predicts bounding boxes and class probabilities directly from full images in one evaluation. Since the whole detection pipeline is a single network, it can be optimized end-to-end directly on detection performance. Our unified architecture is extremely fast. Our base YOLO model processes images in real-time at 45 frames per second. A smaller version of the network, Fast YOLO, processes an astounding 155 frames per second while still achieving double the mAP of other real-time detectors. Compared to state-of-the-art detection systems, YOLO makes more localization errors but is less likely to predict false positives on background. Finally, YOLO learns very general representations of objects. It outperforms other detection methods, including DPM and R-CNN, when generalizing from natural images to other domains like artwork.},
archivePrefix = {arXiv},
arxivId = {1506.02640},
author = {Redmon, Joseph and Divvala, Santosh and Girshick, Ross and Farhadi, Ali},
doi = {10.1109/CVPR.2016.91},
eprint = {1506.02640},
file = {:C\:/Users/febri/AppData/Local/Mendeley Ltd/Mendeley Desktop/Downloaded/Redmon et al. - 2016 - You Only Look Once Unified, Real-Time Object Detection.pdf:pdf},
isbn = {9781467388504},
issn = {10636919},
journal = {Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
pages = {779--788},
title = {{You Only Look Once: Unified, Real-Time Object Detection}},
volume = {2016-Decem},
year = {2016}
}
@article{Zhou2021,
abstract = {As the most basic protection for workers, safety helmets have great significance to workers' lives. However, due to a lack of safety awareness, safety helmets are often not worn. With the continuous development of object detection technology, the YOLO series of algorithms with very high precision and speed has been used in various scene detection tasks. To establish a digital safety helmet monitoring system, we propose a safety helmet detection method based on YOLOv5 and annotate the 6045 collected data sets. Finally, we used the YOLOv5 model with different parameters for training and testing. The four models are compared and analyzed. Experimental results show that the average detection speed of YOLOv5s reaches 110 FPS. Fully meet the requirements of real-time detection. Using the trainable target detector's pre-training weight, the mAP of YOLOv5x reaches 94.7%, proving the effectiveness of helmet detection based YOLOv5.},
author = {Zhou, Fangbo and Zhao, Huailin and Nie, Zhen},
doi = {10.1109/ICPECA51329.2021.9362711},
file = {:C\:/Users/febri/Desktop/Melanoma/paper/zhou2021.pdf:pdf},
isbn = {9781728190037},
journal = {Proceedings of 2021 IEEE International Conference on Power Electronics, Computer Applications, ICPECA 2021},
keywords = {Object detection,Real-time detection,Safety helmet detection,YOLOv5},
pages = {6--11},
title = {{Safety Helmet Detection Based on YOLOv5}},
year = {2021}
}
@article{Popescu2022,
author = {Popescu, Dan; and El-Khatib, Mohamed; and El-Khatib, Hassan; and Ichim, Loretta;},
file = {:E\:/Skripsi/Previous Articles/Popescu El-Khatib Dkk Review SL2015-2021 2022.pdf:pdf},
journal = {Sensors},
keywords = {citation,classifiers,d,deep learning,el-khatib,h,ichim,image,image processing,image segmentation,l,m,machine learning,melanoma detection,neural networks,new trends,popescu,review,skin lesion,statistic performances},
title = {{New Trends in Melanoma Detection Using Neural Networks : A Systematic Review}},
year = {2022}
}
@article{Zhang2021,
author = {Zhang, J and Huang, Yun and Zhang, Xiaobo and Xue, Yan and Bi, Xinling and Chen, Zhuo},
file = {:E\:/Skripsi/Previous Articles/Zhang Huang Dkk YOLOv3 BCC Bowen 2021.pdf:pdf},
keywords = {basal cell carcinoma,bowen,digital pathology,object detection,s disease,yolo},
title = {{Improved YOLO v3 Network for Basal Cell Carcinomas and Bowen ' s Disease Detection}},
year = {2021}
}
@article{Davis2021,
author = {Davis, Dianne S and Robinson, Camille and Callender, Valerie D},
doi = {10.1016/j.ijwd.2021.01.017},
issn = {2352-6475},
journal = {International Journal of Women's Dermatology},
number = {2},
pages = {127--134},
publisher = {The Authors},
title = {{International Journal of Women ' s Dermatology Skin cancer in women of color : Epidemiology , pathogenesis and clinical manifestations}},
volume = {7},
year = {2021}
}
@article{Shorten2019,
abstract = {Deep convolutional neural networks have performed remarkably well on many Computer Vision tasks. However, these networks are heavily reliant on big data to avoid overfitting. Overfitting refers to the phenomenon when a network learns a function with very high variance such as to perfectly model the training data. Unfortunately, many application domains do not have access to big data, such as medical image analysis. This survey focuses on Data Augmentation, a data-space solution to the problem of limited data. Data Augmentation encompasses a suite of techniques that enhance the size and quality of training datasets such that better Deep Learning models can be built using them. The image augmentation algorithms discussed in this survey include geometric transformations, color space augmentations, kernel filters, mixing images, random erasing, feature space augmentation, adversarial training, generative adversarial networks, neural style transfer, and meta-learning. The application of augmentation methods based on GANs are heavily covered in this survey. In addition to augmentation techniques, this paper will briefly discuss other characteristics of Data Augmentation such as test-time augmentation, resolution impact, final dataset size, and curriculum learning. This survey will present existing methods for Data Augmentation, promising developments, and meta-level decisions for implementing Data Augmentation. Readers will understand how Data Augmentation can improve the performance of their models and expand limited datasets to take advantage of the capabilities of big data.},
author = {Shorten, Connor and Khoshgoftaar, Taghi M.},
doi = {10.1186/s40537-019-0197-0},
file = {:C\:/Users/febri/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Shorten, Khoshgoftaar - 2019 - A survey on Image Data Augmentation for Deep Learning.pdf:pdf},
issn = {21961115},
journal = {Journal of Big Data},
keywords = {Big data,Data Augmentation,Deep Learning,GANs,Image data},
number = {1},
publisher = {Springer International Publishing},
title = {{A survey on Image Data Augmentation for Deep Learning}},
url = {https://doi.org/10.1186/s40537-019-0197-0},
volume = {6},
year = {2019}
}
@article{Codella2018,
abstract = {This article describes the design, implementation, and results of the latest installment of the dermoscopic image analysis benchmark challenge. The goal is to support research and development of algorithms for automated diagnosis of melanoma, the most lethal skin cancer. The challenge was divided into 3 tasks: lesion segmentation, feature detection, and disease classification. Participation involved 593 registrations, 81 pre-submissions, 46 finalized submissions (including a 4-page manuscript), and approximately 50 attendees, making this the largest standardized and comparative study in this field to date. While the official challenge duration and ranking of participants has concluded, the dataset snapshots remain available for further research and development.},
archivePrefix = {arXiv},
arxivId = {1710.05006},
author = {Codella, Noel C.F. and Gutman, David and Celebi, M. Emre and Helba, Brian and Marchetti, Michael A. and Dusza, Stephen W. and Kalloo, Aadi and Liopyris, Konstantinos and Mishra, Nabin and Kittler, Harald and Halpern, Allan},
doi = {10.1109/ISBI.2018.8363547},
eprint = {1710.05006},
file = {:E\:/Skripsi/Previous Articles//Codella et al. - 2018 - Skin lesion analysis toward melanoma detection A challenge at the 2017 International symposium on biomedical ima.pdf:pdf},
isbn = {9781538636367},
issn = {19458452},
journal = {Proceedings - International Symposium on Biomedical Imaging},
keywords = {Challenge,Dataset,Deep learning,Dermatology,Dermoscopy,Melanoma,Skin cancer},
pages = {168--172},
title = {{Skin lesion analysis toward melanoma detection: A challenge at the 2017 International symposium on biomedical imaging (ISBI), hosted by the international skin imaging collaboration (ISIC)}},
volume = {2018-April},
year = {2018}
}
@article{Carr2020,
abstract = {The incidence of melanoma continues to increase worldwide. In the United States, melanoma is the fifth most common cancer in men and the sixth most common cancer in women. The risk factors contributing to melanoma have largely remained unchanged, but there is a new focus on modifiable risk factors including sun exposure and ultraviolet light. A large public initiative supported by the Centers for Disease Control focuses on educating the public on the risks of sun exposure and indoor tanning. Early detection and resection of melanoma lesions is necessary to prevent metastasis and reduce medical costs.},
author = {Carr, Stephanie and Smith, Christy and Wernberg, Jessica},
doi = {10.1016/j.suc.2019.09.005},
file = {:C\:/Users/febri/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Carr, Smith, Wernberg - 2020 - Epidemiology and Risk Factors of Melanoma.pdf:pdf},
issn = {15583171},
journal = {Surgical Clinics of North America},
keywords = {Carcinogen,Indoor tanning,Melanoma,Prevention,Ultraviolet radiation},
number = {1},
pages = {1--12},
pmid = {31753105},
publisher = {Elsevier Inc},
title = {{Epidemiology and Risk Factors of Melanoma}},
url = {https://doi.org/10.1016/j.suc.2019.09.005},
volume = {100},
year = {2020}
}
@article{Arab2020,
abstract = {Objectives: To assess the prevalence of melanoma and non-melanoma skin cancer for patients attended King Khalid University Hospital, Riyadh, Saudi Arabia. We are also assessing the most common category of skin cancer to be encountered among those patients. Methods: The authors conducted a retrospective study including all patients (Saudi and non-Saudi) who attended King Khalid University Hospital (KKUH) at the period of (2007-2018). Data were collected from archives of Pathology Department at KKUH and categorized into: melanoma skin cancer (MSC), non-melanoma skin cancer (NMSC), which included: basal cell carcinoma (BCC) and squamous cell carcinoma (SCC), pre-neoplastic lesions, and non-neoplastic skin lesions. Results: A total of 111 patients were reported to have skin cancer out of 9828 cases, which had other skin pathology. Majority of cases were basal cell carcinoma with a total number of 76 (68.5%) of all cases. 18 patients (16.2%) were diagnosed with MSC. The remaining 17 patients (15.3%) were diagnosed with squamous cell carcinoma. Conclusion: Skin cancer prevalence and incidence is increasing worldwide. In our study, BCC was the most common type of skin cancer to be reported in our institute, which is similar to the majority of other international studies.},
author = {Arab, Khalid A. and AlRuhaili, Amjad and AlJohany, Tariq and AlHammad, Reema S.},
doi = {10.15537/SMJ.2020.7.25138},
file = {:C\:/Users/febri/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Arab et al. - 2020 - Melanoma and non-melanoma skin cancer among patients who attended at King Khalid University Hospital in Riyadh, Sau.pdf:pdf},
issn = {16583175},
journal = {Saudi Medical Journal},
keywords = {BCC,KKUH,MSC,NMSC,SCC},
number = {7},
pages = {709--714},
pmid = {32601638},
title = {{Melanoma and non-melanoma skin cancer among patients who attended at King Khalid University Hospital in Riyadh, Saudi Arabia from 2007 - 2018}},
volume = {41},
year = {2020}
}
@article{Unver2019,
author = {{\"{U}}nver, Halil Murat and Ayan, Enes},
file = {:C\:/Users/febri/Desktop/Melanoma/paper/diagnostics-09-00072.pdf:pdf},
keywords = {convolutional neural networks,melanoma,skin cancer,skin lesion segmentation},
title = {{Skin Lesion Segmentation in Dermoscopic Images with Combination of YOLO and GrabCut Algorithm}},
year = {2019}
}
@article{Gunawan2022,
abstract = {Now-a-days, coronary heart disease is one of the deadliest diseases in the world. An unfavorable lifestyle, lack of physical activity, and consuming tobacco are the causes of coronary heart disease aside from genetic inheritance. Sometimes the patient does not know whether he has abnormalities in heart function or not. Therefore, this study proposes a system that can detect heart abnormalities through the iris, known as the Iridology method. The system is designed automatically in the iris detection to the classification results. Feature extraction using five characteristics is applied to the Gray Level Co-occurrence Matrix (GLCM) method. The classification process uses the Support Vector Machine (SVM) with linear kernel variation, Polynomial, and Gaussian to obtain the best accuracy in the system. From the system simulation results, the use of the Gaussian kernel can be relied on in the classification of iris conditions with an accuracy rate of 91%, then the Polynomial kernel accuracy reaches 89%, and the linear kernel accuracy reaches 87%. This study has succeeded in detecting heart conditions through the iris by dividing the iris into normal iris and abnormal iris},
author = {Gunawan, Vincentius Abdi and Putra, Leonardus Sandy Ade and Imansyah, Fitri and Kusumawardhani, Eka},
doi = {10.14569/IJACSA.2022.0130177},
file = {:C\:/Users/febri/Downloads/Documents/Paper_77-Identification_of_Coronary_Heart_Disease.pdf:pdf},
issn = {21565570},
journal = {International Journal of Advanced Computer Science and Applications},
keywords = {Circle hough transform,Coronary heart,Gray level co-occurrence matrix,Iridology,Iris,Support vector machine},
number = {1},
pages = {639--648},
title = {{Identification of Coronary Heart Disease through Iris using Gray Level Co-occurrence Matrix and Support Vector Machine Classification}},
volume = {13},
year = {2022}
}
@article{Milton2019,
abstract = {In this paper, we studied extensively on different deep learning based methods to detect melanoma and skin lesion cancers. Melanoma, a form of malignant skin cancer is very threatening to health. Proper diagnosis of melanoma at an earlier stage is crucial for the success rate of complete cure. Dermoscopic images with Benign and malignant forms of skin cancer can be analyzed by computer vision system to streamline the process of skin cancer detection. In this study, we experimented with various neural networks which employ recent deep learning based models like PNASNet-5-Large, InceptionResNetV2, SENet154, InceptionV4. Dermoscopic images are properly processed and augmented before feeding them into the network. We tested our methods on International Skin Imaging Collaboration (ISIC) 2018 challenge dataset. Our system has achieved best validation score of 0.76 for PNASNet-5-Large model. Further improvement and optimization of the proposed methods with a bigger training dataset and carefully chosen hyper-parameter could improve the performances. The code available for download at https://github.com/miltonbd/ISIC_2018_classification},
archivePrefix = {arXiv},
arxivId = {1901.10802},
author = {Milton, Md Ashraful Alam},
eprint = {1901.10802},
file = {:C\:/Users/febri/Desktop/Melanoma/paper/Milton 2019.pdf:pdf},
title = {{Automated Skin Lesion Classification Using Ensemble of Deep Neural Networks in ISIC 2018: Skin Lesion Analysis Towards Melanoma Detection Challenge}},
url = {http://arxiv.org/abs/1901.10802},
year = {2019}
}
@book{ElAmri2019,
abstract = {The unpredictable emergence of new zoonotic diseases with viral etiology is currently a hot issue in the scientific and political circles. Viral emergence and reemergence, as a sanitary event, are only the visible part of the iceberg, while the hidden one corresponds to a multitude of complex and interrelated factors, including societal and environmental factors favoring the advent of the state of viral emergence and reemergence. According to the World Health Organization, 60% of the agents recognized as human pathogens come from the animal kingdom, and 75% of the pathogens responsible for emerging and reemerging animal diseases present a potential transgression of interface between interspecies establishing favorable conditions for genetic exchange leading to the emergence of new highly pathogenic variants and strains of which the animal is often the host reservoir. Therefore any public health prophylactic strategy requires a holistic approach to the health problem, taking into account the interaction between the triad elements of the human, animal, and environment. This globalized approach has been realized by the international community through the new recently established concept of “One Health, One World,” making the old bipolar concept of separated human and animal health issues avoided and obsolete. The extreme diversity of emerging and reemerging viral pathogens, the change of human lifestyle, the globalization of travel, business exchanges, and tourism potentiate the risk of emergence of highly pathogenic zoonotic diseases. Promoting intersectorial collaboration will allow to unify the health and safety policies. The cross-cutting ecological and health data at the national and global scales are effective means for sustaining good health in human, animal, and ecosystem (in particular the viral ecology).},
author = {{El Amri}, Hamid and Boukharta, Mohamed and Zakham, Fathiah and Ennaji, Moulay Mustapha},
booktitle = {Emerging and Reemerging Viral Pathogens: Volume 1: Fundamental and Basic Virology Aspects of Human, Animal and Plant Pathogens},
doi = {10.1016/B978-0-12-819400-3.00027-2},
file = {:C\:/Users/febri/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/El Amri et al. - 2019 - Emergence and reemergence of viral zoonotic diseases Concepts and factors of emerging and reemerging globalizati.pdf:pdf},
isbn = {9780128194003},
keywords = {Emergence,One health,One world,Reemergence,Virus,Zoonoses},
pages = {619--634},
publisher = {Elsevier Inc.},
title = {{Emergence and Reemergence of Viral Zoonotic Diseases: Concepts and Factors of Emerging and Reemerging Globalization of Health Threats}},
url = {http://dx.doi.org/10.1016/B978-0-12-819400-3.00027-2},
year = {2019}
}
@article{Kharis2019,
abstract = {A World Health Organization reported that the mortality rate due to brain cancer is the highest in the Asian continent. It is critical importance that brain cancer can be detected earlier so that the treatment process can be carried out more precisely and will be able to extend the life expectancy of brain cancer patients. Taking advantage of microarray data, machine learning methods can be applied to help brain cancer prediction according to its type. This problem can be referred to as a multiclass classification problem. Using the one versus one approach, there will be as many as k(k-1)/2 two-class problems, where k indicates the number of classes. In this paper, Multiple Multiclass Artificial Bee Colony (MMABC) implemented as a feature selection method and Support Vector Machine (SVM) as a classification method. ABC algorithm proved successful in solving optimisation problems with high dimensionality, and SVM can produce accurate and robust classification results. The data obtained from Broad Institute data. The data consist of 7129 features and 42 samples. From the experiment, the accuracy of Multiple SVM using a feature selection based MMABC method reached 95.24% accuracy in usage 300 best features; this percentage slightly more superior than SVM method without feature selection.},
author = {Kharis, S. A.A. and Hadi, I. and Hasanah, K. A.},
doi = {10.1088/1742-6596/1417/1/012015},
file = {:C\:/Users/febri/Desktop/Melanoma/paper/Kharis Dkk 2019.pdf:pdf},
issn = {17426596},
journal = {Journal of Physics: Conference Series},
number = {1},
title = {{Multiclass Classification of Brain Cancer with Multiple Multiclass Artificial Bee Colony Feature Selection and Support Vector Machine}},
volume = {1417},
year = {2019}
}
@article{Zhang2019a,
author = {Zhang, Ni and Cai, Yi-xin and Wang, Yong-yong and Tian, Yi-tao and Wang, Xiao-li and Badami, Benjamin},
doi = {10.1016/j.artmed.2019.101756},
file = {:C\:/Users/febri/Desktop/Melanoma/paper/Zhang Cai Dkk 2019.pdf:pdf},
issn = {0933-3657},
journal = {Artificial Intelligence In Medicine},
publisher = {Elsevier B.V.},
title = {{Skin Cancer Diagnosis Based on Optimized Convolutional Neural Network}},
url = {https://doi.org/10.1016/j.artmed.2019.101756},
year = {2019}
}
@article{Sung2021,
abstract = {This article provides an update on the global cancer burden using the GLOBOCAN 2020 estimates of cancer incidence and mortality produced by the International Agency for Research on Cancer. Worldwide, an estimated 19.3 million new cancer cases (18.1 million excluding nonmelanoma skin cancer) and almost 10.0 million cancer deaths (9.9 million excluding nonmelanoma skin cancer) occurred in 2020. Female breast cancer has surpassed lung cancer as the most commonly diagnosed cancer, with an estimated 2.3 million new cases (11.7%), followed by lung (11.4%), colorectal (10.0 %), prostate (7.3%), and stomach (5.6%) cancers. Lung cancer remained the leading cause of cancer death, with an estimated 1.8 million deaths (18%), followed by colorectal (9.4%), liver (8.3%), stomach (7.7%), and female breast (6.9%) cancers. Overall incidence was from 2-fold to 3-fold higher in transitioned versus transitioning countries for both sexes, whereas mortality varied <2-fold for men and little for women. Death rates for female breast and cervical cancers, however, were considerably higher in transitioning versus transitioned countries (15.0 vs 12.8 per 100,000 and 12.4 vs 5.2 per 100,000, respectively). The global cancer burden is expected to be 28.4 million cases in 2040, a 47% rise from 2020, with a larger increase in transitioning (64% to 95%) versus transitioned (32% to 56%) countries due to demographic changes, although this may be further exacerbated by increasing risk factors associated with globalization and a growing economy. Efforts to build a sustainable infrastructure for the dissemination of cancer prevention measures and provision of cancer care in transitioning countries is critical for global cancer control.},
author = {Sung, Hyuna and Ferlay, Jacques and Siegel, Rebecca L. and Laversanne, Mathieu and Soerjomataram, Isabelle and Jemal, Ahmedin and Bray, Freddie},
doi = {10.3322/caac.21660},
file = {:C\:/Users/febri/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Sung et al. - 2021 - Global Cancer Statistics 2020 GLOBOCAN Estimates of Incidence and Mortality Worldwide for 36 Cancers in 185 Countri.pdf:pdf},
issn = {0007-9235},
journal = {CA: A Cancer Journal for Clinicians},
month = {may},
number = {3},
pages = {209--249},
pmid = {33538338},
publisher = {Wiley},
title = {{Global Cancer Statistics 2020: GLOBOCAN Estimates of Incidence and Mortality Worldwide for 36 Cancers in 185 Countries}},
volume = {71},
year = {2021}
}
@article{Islam2020,
abstract = {Human skin is continuously subjected to environmental stresses, as well as extrinsic and intrinsic noxious agents. Although skin adopts various molecular mechanisms to maintain homeostasis, excessive and repeated stresses can overwhelm these systems, leading to serious cutaneous damage, including both melanoma and non‐melanoma skin cancers. Phytochemicals present in the diet possess the desirable effects of protecting the skin from damaging free radicals as well as other benefits. Dietary phytochemicals appear to be effective in preventing skin cancer and are inexpensive, widely available, and well tolerated. Multiple in vitro and in vivo studies have demonstrated the significant anti‐inflammatory, antioxidant, and anti‐angiogenic characteristics of dietary phytochemicals against skin malignancy. Moreover, dietary phytochemicals affect multiple important cellular processes including cell cycle, angiogenesis, and metastasis to control skin cancer progression. Herein, we discuss the advantages of key dietary phytochemicals in whole fruits and vegetables, their bioavailability, and underlying molecular mechanisms for preventing skin cancer. Current challenges and future prospects for research are also reviewed. To date, most of the chemoprevention investigations have been conducted preclinically, and additional clinical trials are required to conform and validate the preclinical results in humans.},
author = {Islam, Salman Ul and Ahmed, Muhammad Bilal and Ahsan, Haseeb and Islam, Mazharul and Shehzad, Adeeb and Sonn, Jong Kyung and Lee, Young Sup},
doi = {10.3390/antiox9100916},
file = {:C\:/Users/febri/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Islam et al. - 2020 - An update on the role of dietary phytochemicals in human skin cancer New insights into molecular mechanisms.pdf:pdf},
issn = {20763921},
journal = {Antioxidants},
keywords = {Chemoprevention,Dietary phytochemicals,Free radicals,Melanoma,Skin carcinogenesis,UV radiation},
number = {10},
pages = {1--30},
title = {{An update on the role of dietary phytochemicals in human skin cancer: New insights into molecular mechanisms}},
volume = {9},
year = {2020}
}
@article{Nersisson2021,
author = {Nersisson, Ruban and Iyer, Tharun J and Noel, Alex Noel Joseph and Rajangam, Vijayarajan},
doi = {10.1007/s13369-021-05571-1},
file = {:E\:/Skripsi/Previous Articles//Nersisson et al. - 2021 - A Dermoscopic Skin Lesion Classification Technique Using YOLO-CNN and Traditional Feature Model.pdf:pdf},
issn = {2191-4281},
journal = {Arabian Journal for Science and Engineering},
keywords = {Convolutional neural netw,Dermoscopic skin lesions,convolutional neural network,dermoscopic skin lesions,feature fusion,transfer learning,yolo},
number = {10},
pages = {9797--9808},
publisher = {Springer Berlin Heidelberg},
title = {{A Dermoscopic Skin Lesion Classification Technique Using YOLO-CNN and Traditional Feature Model}},
url = {https://doi.org/10.1007/s13369-021-05571-1},
volume = {46},
year = {2021}
}
@article{Jha2019,
abstract = {Data mining (DM) is the process of retrieving information from huge data-sets and transforming them into meaningful decision. Classification technique is considered to be the most important data mining techniques as it becoming an enthralling topic to the scholars that precisely and effectively describes data for the knowledge-discovery. It is used to describe and distinguish data classes or concepts. There are two major classes of classification problems: Binary-class and Multi-class. In Binary-class classifications, the given data-set is categorized into two classes whereas in Multi-class classification, the given data-set is categorized into several classes based on the classification rules. This paper explores several DM classification approaches such as Decision tree like Classification and Regression Tree(CART) and Conditional Inference Tree(CTREE), Random Forest(RF), Support Vector Machine(SVM) and k-Nearest-Neighbour(KNN) to enhance the result of binary class and multi-class classifiers using the powerful Big data mining analytical tool R and RStudio. Various measures such as Accuracy, F-Score, Sensitivity etc. are used to evaluate the classifier's performance and also predict which classifier will perform better when the training-testing data-sets are analysed with multiple partitions (%).},
author = {Jha, Anupama and Dave, Meenu and Madan, Supriya},
doi = {10.2139/ssrn.3464211},
file = {:C\:/Users/febri/Desktop/Melanoma/paper/Jha Dave Dkk 2019.pdf:pdf},
journal = {SSRN Electronic Journal},
pages = {894--903},
title = {{Comparison of Binary Class and Multi-Class Classifier Using Different Data Mining Classification Techniques}},
year = {2019}
}
@article{Hasan2019,
abstract = {Skin cancer is known as one of the most risky types of cancer. Several kinds of skin cancer, such as melanoma, basal and squamous cell carcinoma, etc., are available. The most unpredictable cancer is melanoma. If we can detect melanoma skin cancer at an early stage, the chances of recovery will be good and we can save many valuable lives. But if we fail to detect early, melanoma can disperse to the different parts of the body and chance of recovery will become difficult. This research presents a developed system to do melanoma diagnosis by using several dermoscopy images. In this research, we preprocessed the images to remove hairs and noises by using some filter techniques such as dull razor technique, median filtering, etc. After that, we segmented the image to find the infected area using some segmentation method and we choose the method that will give us the best results. Then we post-process the images and choose the most infected lesion. After segmentation of the skin lesion, we checked the segmentation accuracy concerning some basic criteria. We compared the segmented skin lesions with the marked skin lesions by a dermatologist. Then we extracted the features of the images of different criteria, such as Asymmetry, Border irregularity, Color variance, Diameter which have the acronym as ABCD. We also analyzed the texture of the lesions and extracted the geometrical features. Finally, we choose decision tree classification methods that gave us the best results.},
author = {Hasan, Mahmudul and Mohsin, Mohammad and Chowdhury, Md Kamal Hossain},
doi = {10.35940/ijrte.C4561.098319},
file = {:E\:/Skripsi/Previous Articles/Hasan, Mohsin, Chowdhury - 2019 - Automatic detection and analysis of Melanoma skin cancer using dermoscopy images.pdf:pdf},
issn = {22773878},
journal = {International Journal of Recent Technology and Engineering},
keywords = {Feature extraction,Image segmentation,Object recognition,Pattern clustering,Pattern matching},
number = {3},
pages = {2116--2122},
title = {{Automatic Detection and Analysis of Melanoma Skin Cancer using Dermoscopy Images}},
volume = {8},
year = {2019}
}
@article{Majumder2019,
abstract = {Melanoma is the deadliest type of skin cancer. It has been rising exponentially for the last few decades. If it is diagnosed and treated at its early stage, the survival rate is very high. To prevent the invasive biopsy technique, automated diagnosis of melanoma from dermoscopy images has become a hot research area for the last few decades. This paper proposes three new distinct and effective features with some existing features related to shape, size and color properties of dermoscopy images based on ABCD rule for melanoma detection. ABCD stands for Asymmetry, Border, Color, and Diameter of the skin lesion. A two-stage segmentation approach including Otsu algorithm and Chan–Vese algorithm for lesion segmentation is implemented in this paper. Dull-Razor algorithm removes the black and dark hair from the input images and artificial neural network classifier classifies the malignant and benign images based on the extracted features. Implementation result of the proposed approach achieves 98.2% overall classification accuracy with 98% sensitivity and 98.2% specificity. These promising results indicate that the proposed system is able to assist the dermatologists in early detection of melanoma.},
author = {Majumder, Sharmin and Ullah, Muhammad Ahsan},
doi = {10.1007/s42452-019-0786-8},
file = {:C\:/Users/febri/Desktop/Melanoma/paper/Majumder Ullah 2019.pdf:pdf},
isbn = {0123456789},
issn = {25233971},
journal = {SN Applied Sciences},
keywords = {Artificial neural network,Dermoscopy images,Digital image processing,Feature extraction,Melanoma,Skin cancer,Skin lesion},
number = {7},
pages = {1--11},
publisher = {Springer International Publishing},
title = {{Feature Extraction from Dermoscopy Images for Melanoma Diagnosis}},
url = {https://doi.org/10.1007/s42452-019-0786-8},
volume = {1},
year = {2019}
}
@article{Rezvantalab2018,
abstract = {In this paper, the effectiveness and capability of convolutional neural networks have been studied in the classification of 8 skin diseases. Different pre-trained state-of-the-art architectures (DenseNet 201, ResNet 152, Inception v3, InceptionResNet v2) were used and applied on 10135 dermoscopy skin images in total (HAM10000: 10015, PH2: 120). The utilized dataset includes 8 diagnostic categories - melanoma, melanocytic nevi, basal cell carcinoma, benign keratosis, actinic keratosis and intraepithelial carcinoma, dermatofibroma, vascular lesions, and atypical nevi. The aim is to compare the ability of deep learning with the performance of highly trained dermatologists. Overall, the mean results show that all deep learning models outperformed dermatologists (at least 11%). The best ROC AUC values for melanoma and basal cell carcinoma are 94.40% (ResNet 152) and 99.30% (DenseNet 201) versus 82.26% and 88.82% of dermatologists, respectively. Also, DenseNet 201 had the highest macro and micro averaged AUC values for overall classification (98.16%, 98.79%, respectively).},
archivePrefix = {arXiv},
arxivId = {1810.10348},
author = {Rezvantalab, Amirreza and Safigholi, Habib and Karimijeshni, Somayeh},
eprint = {1810.10348},
file = {:C\:/Users/febri/Desktop/Melanoma/paper/Rezvantalab Safigholi Dkk DCNN HAM10000 2018.pdf:pdf},
title = {{Dermatologist Level Dermoscopy Skin Cancer Classification Using Different Deep Learning Convolutional Neural Networks Algorithms}},
url = {http://arxiv.org/abs/1810.10348},
year = {2018}
}
@article{KrishnaMonika2020,
abstract = {Skin cancer is considered as one of the most dangerous types of cancers and there is a drastic increase in the rate of deaths due to lack of knowledge on the symptoms and their prevention. Thus, early detection at premature stage is necessary so that one can prevent the spreading of cancer. Skin cancer is further divided into various types out of which the most hazardous ones are Melanoma, Basal cell carcinoma and Squamous cell carcinoma. This project is about detection and classification of various types of skin cancer using machine learning and image processing tools. In the pre-processing stage, dermoscopic images are considered as input. Dull razor method is used to remove all the unwanted hair particles on the skin lesion, then Gaussian filter is used for image smoothing. For noise filtering and to preserve the edges of the lesion, Median filter is used. Since color is an important feature in analyzing the type of cancer, color-based k-means clustering is performed in segmentation phase. The statistical and texture feature extraction is implemented using Asymmetry, Border, Color, Diameter, (ABCD) and Gray Level Co-occurrence Matrix (GLCM). The experimental analysis is conduted on ISIC 2019 Challenge dataset consisting of 8 different types of dermoscopic images. For classification purpose, Multi-class Support Vector Machine (MSVM) was implemented and the accuracy obtained is about 96.25.},
author = {{Krishna Monika}, M. and {Arun Vignesh}, N. and {Usha Kumari}, Ch and Kumar, M. N.V.S.S. and {Laxmi Lydia}, E.},
doi = {10.1016/j.matpr.2020.07.366},
file = {:C\:/Users/febri/Desktop/Melanoma/paper/monika2020.pdf:pdf},
issn = {22147853},
journal = {Materials Today: Proceedings},
keywords = {ABCD method,Classification,Dermoscopic images,Dull razor method,Feature extraction,Filters,GLCM method,MSVM},
number = {xxxx},
pages = {4266--4270},
publisher = {Elsevier Ltd},
title = {{Skin cancer detection and classification using machine learning}},
url = {https://doi.org/10.1016/j.matpr.2020.07.366},
volume = {33},
year = {2020}
}
@article{Ratnasari2019,
abstract = {Basal Cell Carcinoma (KSB) is a deadly skin cancer that has become one of the most common diseases. This disease generally occurs in areas of the skin that are often exposed to sunlight such as the face and neck. Basal cell carcinoma usually appears after more than 40 years of age, although it can also be found in children and adolescents rarely. If not treated immediately, basal cell carcinoma will spread locally, resulting in substantial tissue damage which causes impaired function. So we need the right steps in handling itThe purpose of designing this application is to detect basal cell carcinoma skin cancer on an Android-based device. In Paper, the authors discusses ways to overcome this problem by using the ABCD Feature extraction and K-Nearest Neighbor (KNN) as a classification. This application has a user friendly application display because it was developed using a platform that can be used by all circles of science, so users do not need a qualified IT skills. The results of this study are beneficial to the community, which can be used by the community and can find out whether or not KSB is detected or not. From the results of tests that have been done, the results of feature extraction accuracy get an accuracy of 91,6%.},
author = {Ratnasari, Deva and Irawan, Budhi and Setianingsih, Casi},
doi = {10.1109/ICAMIMIA47173.2019.9223382},
file = {:E\:/Skripsi/Previous Articles/Ratnasari, Irawan, Setianingsih - 2019 - Early Detection of Superficial Basal-Cell Carcinoma Skin Cancer with Extraction Method ABCD Fea.pdf:pdf},
isbn = {9781728130903},
journal = {2019 International Conference on Advanced Mechatronics, Intelligent Manufacture and Industrial Automation, ICAMIMIA 2019 - Proceeding},
keywords = {ABCD Feature,BCC,KNN},
pages = {134--140},
title = {{Early Detection of Superficial Basal-Cell Carcinoma Skin Cancer with Extraction Method ABCD Feature Based on Android}},
year = {2019}
}
@article{Budhiman2019,
abstract = {Melanoma skin cancer is cancer that difficult to detect. In this study, have been done melanoma cancer classification using Convolutional Neural Network (CNN). CNN is a class of Deep Neural Network (Deep Learning) and commonly used to analyzing images data. A lot of data used on CNN can greatly affect accuracy. In this study, the objective is to get best ResNet model for classifying melanoma cancer and normal skin images. The dataset that used is ISIC 2018. ResNet is used because the model winning the ILSVRC competition at 2015. ResNet architecture model that used are ResNet 50, 40, 25, 10 and 7 models. The architecture trained using data train that has been augmented and undersampling. The validation result on each model calculated using F1 Score. After validation and F1 Score result from the model obtained, the result compared each other to select the best model. The best architecture is ResNet 50 without augmentation that gives a validation accuracy of 0.83 and f1 score of 0.46.},
author = {Budhiman, Arief and Suyanto, Suyanto and Arifianto, Anditya},
doi = {10.1109/ISRITI48646.2019.9034624},
file = {:C\:/Users/febri/Desktop/Melanoma/paper/Budhiman Suyanto Dkk Resnet ISIC2018 2019.pdf:pdf},
isbn = {9781728145204},
journal = {2019 2nd International Seminar on Research of Information Technology and Intelligent Systems, ISRITI 2019},
keywords = {ResNet,data augmentation,dropout,fully-connected layer},
pages = {17--20},
publisher = {IEEE},
title = {{Melanoma Cancer Classification Using ResNet with Data Augmentation}},
year = {2019}
}
@article{Hasan2021,
author = {Hasan, Mohammed Rakeibul and Fatemi, Mohammed Ishraaf and Khan, Mohammad Monirujjaman and Kaur, Manjit and Zaguia, Atef},
doi = {https://doi.org/10.1155/2021/5895156},
journal = {Journal of Healthcare Engineering},
title = {{Comparative Analysis of Skin Cancer ( Benign vs . Malignant ) Detection Using Convolutional Neural Networks}},
volume = {2021},
year = {2021}
}
@article{Gavrilov2018,
author = {Gavrilov, D. A. and Zakirov, E. I. and Gameeva., E. V. and Semenov, Yu. and Aleksandrova, O. Yu.},
doi = {10.17709/2409},
journal = {Research and Practical Medicine Journal},
number = {3},
pages = {110--116},
title = {{Automated skin melanoma diagnostics based on mathematical model of artificial convolutional neural network}},
volume = {5},
year = {2018}
}
@article{Demir2019,
author = {Demir, Ahmet; and Yilmaz, Feyza; and Kose, Onur},
file = {:C\:/Users/febri/Desktop/Melanoma/paper/Demir Yilmaz 2019.pdf:pdf},
isbn = {9781728124209},
keywords = {classification,inception-,resnet-121,skin cancer},
pages = {3--6},
title = {{Early Detection of Skin Cancer Using Deep Learning Architectures : Resnet-101 and Inception-v3}},
year = {2019}
}
@article{Pacheco2019,
archivePrefix = {arXiv},
arxivId = {arXiv:1909.04525v2},
author = {Pacheco, Andre G C and Ali, Abder-rahman and Trappenberg, Thomas},
eprint = {arXiv:1909.04525v2},
file = {:C\:/Users/febri/Desktop/Melanoma/paper/Pacheco Ali Dkk 2019.pdf:pdf},
journal = {ISIC Challenge},
pages = {1--6},
title = {{Skin Cancer Detection Based on Deep Learning and Entropy to Detect Outlier Samples}},
year = {2019}
}
@article{Ahmed2019,
abstract = {Leukemia is a fatal cancer and has two main types: Acute and chronic. Each type has two more subtypes: Lymphoid and myeloid. Hence, in total, there are four subtypes of leukemia. This study proposes a new approach for diagnosis of all subtypes of leukemia from microscopic blood cell images using convolutional neural networks (CNN), which requires a large training data set. Therefore, we also investigated the effects of data augmentation for an increasing number of training samples synthetically. We used two publicly available leukemia data sources: ALL-IDB and ASH Image Bank. Next, we applied seven different image transformation techniques as data augmentation. We designed a CNN architecture capable of recognizing all subtypes of leukemia. Besides, we also explored other well-known machine learning algorithms such as naive Bayes, support vector machine, k-nearest neighbor, and decision tree. To evaluate our approach, we set up a set of experiments and used 5-fold cross-validation. The results we obtained from experiments showed that our CNN model performance has 88.25% and 81.74% accuracy, in leukemia versus healthy and multi-class classification of all subtypes, respectively. Finally, we also showed that the CNN model has a better performance than other well-known machine learning algorithms.},
author = {Ahmed, Nizar and Yigit, Altug and Isik, Zerrin and Alpkocak, Adil},
doi = {10.3390/diagnostics9030104},
file = {:C\:/Users/febri/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Ahmed et al. - 2019 - Identification of leukemia subtypes from microscopic images using convolutional neural network.pdf:pdf},
issn = {20754418},
journal = {Diagnostics},
keywords = {Convolutional neural network,Data augmentation,Deep learning,Leukemia diagnosis,Microscopic blood cells images,Multi-class classification,Recognizing leukemia subtypes},
number = {3},
title = {{Identification of Leukemia Subtypes from Microscopic Images Using Convolutional Neural Network}},
volume = {9},
year = {2019}
}
@article{AhmedThaajwer2020,
abstract = {In humans, skin cancer is the most common and severe type of cancer. Melanoma is a deadly type of skin cancer. If it identifies early stages, it can be easily cured. The formal method for diagnosing melanoma detection is the biopsy method. This method can be a very painful one and a time-consuming process. This study gives a computer-aided detection system for the early identification of melanoma. In this study, image processing techniques and the Support vector machine (SVM) algorithms are used to introduce an efficient diagnosing system. The affected skin image is taken, and it sent under several pre-processing techniques for getting the enhanced image and smoothed image. Then the image is sent through the segmentation process using morphological and thresholding methods. Some essential texture, color and shape features of the skin images are extracted. Gray Level Co-occurrence Matrix (GLCM) methodology is used for extracting texture features. These extracted GLCM, color and shape features are given as input to the SVM classifier. It classifies the given image into malignant melanoma or benign melanoma. High accuracy of 83% is achieved when we combine and apply the shape, color and GLCM features to the classifier.},
author = {{Ahmed Thaajwer}, M. A. and {Piumi Ishanka}, U. A.},
doi = {10.1109/ICAC51239.2020.9357309},
file = {:C\:/Users/febri/Desktop/Melanoma/paper/169_Melanoma_Skin_Cancer_Detection_using_Image_Processing_and_Machine_Learning20190703-23098-1o8hr8x-with-cover-page-v2.pdf:pdf},
isbn = {9781728184128},
journal = {ICAC 2020 - 2nd International Conference on Advancements in Computing, Proceedings},
keywords = {GLCM,Melanoma,SVM,Segmentation},
pages = {363--368},
title = {{Melanoma skin cancer detection using image processing and machine learning techniques}},
year = {2020}
}
@article{Asasutjarit2021,
abstract = {Andrographolide (AG) is an active compound isolated from Andrographis paniculata (Family Acanthaceae). Although it possesses beneficial bioactivities to the skin, there is insufficient information of its applications for treatment of skin disorders due to low water solubility leading to complications in product development. To overcome the problem, an AG-loaded nanoemulsion (AG-NE) was formulated and prepared using a microfluidization technique. This study aimed to investigate the effect of pressure and the number of homogenization cycles (factors) on droplet size, polydispersity index and zeta potential of AG-NE (responses) and to determine the effect of AG-NE on skin cancer cells and UVB irradiation-induced skin disorders in rats. Relationships between factors versus responses obtained from the face-centered central composite design were described by quadratic models. The optimum value of parameters for the production of optimized AG-NE (Op-AG-NE) were 20,000 psi of pressure and 5 homogenization cycles. Op-AG-NE showed promising cytotoxicity effects on the human malignant melanoma-(A375 cells) and non-melanoma cells (A-431 cells) via apoptosis induction with a high selectivity index and also inhibited intracellular tyrosinase activity in the A375 cells. Op-AG-NE could reduce melanin index and healed UVB irradiation exposed skin. Op-AG-NE thus had potential for treatment of skin cancers and skin disorders from exposure to UVB radiation.},
author = {Asasutjarit, Rathapon and Sooksai, Nawarat and Fristiohady, Adryan and Lairungruang, Kriyapa and Ng, Shiow-Fern and Fuongfuchat, Asira},
doi = {10.3390/pharmaceutics13081290},
file = {:C\:/Users/febri/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Asasutjarit et al. - 2021 - Optimization of Production Parameters for Andrographolide-Loaded Nanoemulsion Preparation by Microfluidizati.pdf:pdf},
issn = {19994923},
journal = {Pharmaceutics},
number = {8},
pages = {1290},
title = {{Optimization of Production Parameters for Andrographolide-Loaded Nanoemulsion Preparation by Microfluidization and Evaluations of Its Bioactivities in Skin Cancer Cells and UVB Radiation-Exposed Skin}},
volume = {13},
year = {2021}
}
@article{Koklu2017,
abstract = {{\ldots} This study has been performed using the functions of MATLAB Statistics and Machine Learning Toolbox and MATLAB {\ldots} 1-4. [18] A. Başt{\"{u}}rk, ME Y{\"{u}}ksel, H. Badem and A. {\c{C}}alışkan, "Deep neural network based diagnosis system for {\ldots} [21] T. Mitchell, "Machine Learning, McGraw-Hill {\ldots}},
author = {Koklu, Murat and Ozkan, Ilker Ali},
doi = {10.18201/ijisae.2017534420},
file = {:C\:/Users/febri/Desktop/Melanoma/paper/Ozkan Koklu ML 2017.pdf:pdf},
isbn = {2017534420},
issn = {2147-6799},
journal = {International Journal of Intelligent Systems and Applications in Engineering},
keywords = {abcd,asymmetrical shape,border,classification,dermatologists usually perform the,diagnosis of melanoma,machine learning methods,medical decision support system,skin lesion,structures and patterns,through these images by,visualization of the morphological},
number = {5},
pages = {285--289},
title = {{Skin Lesion Classification using Machine Learning Algorithms}},
volume = {4},
year = {2017}
}
@article{Museum2019,
abstract = {El presente trabajo de investigaci{\'{o}}n se enfoca el estudio del liderazgo de los microempresarios peruanos respecto al clima organizacional en las empresas pertenecientes al sector PYME; teniendo como finalidad determinar el impacto que genera el liderazgo en el clima organizacional de las empresas PYMES en Lima Metropolitana. En la presente investigaci{\'{o}}n se estudiaron cinco empresas del sector PYME, con un total de 52 colaboradores a los cuales se les aplic{\'{o}} una encuesta de 52 preguntas de acuerdo al modelo del Instrumento para medir el Clima en las Organizaciones Colombianas (IMCOC), dise{\~{n}}ado por M{\'{e}}ndez (2005); el cual mide siete dimensiones, tales como liderazgo, objetivos empresariales, cooperaci{\'{o}}n, toma de decisiones, motivaci{\'{o}}n, control y relaciones interpersonales. Adem{\'{a}}s, se determinar{\'{a}} la percepci{\'{o}}n que tienen los colaboradores acerca del liderazgo ejercido por sus superiores y se establecer{\'{a}} cu{\'{a}}l de las dimensiones del Clima Laboral es m{\'{a}}s importante para ellos. Los hallazgos obtenidos fueron que el liderazgo tiene un impacto considerable con un efecto positivo sobre el clima organizacional, por lo que se debe tener en cuenta para la medici{\'{o}}n del Clima Organizacional y los l{\'{i}}deres deben reconocer que son parte importante de la organizaci{\'{o}}n y que tienen un alto grado de incidencia sobre el clima laboral de sus empresas. De la misma manera, se logr{\'{o}} determinar que la percepci{\'{o}}n que tienen sobre el liderazgo de sus},
author = {Museum, Mizunami Fossil},
file = {:C\:/Users/febri/Desktop/Melanoma/paper/Nie Sommella 2019.pdf:pdf},
keywords = {1981,bivalvia,early miocene,itoigawa et al,japan,mizunami group,pearl},
number = {45},
pages = {95--98},
title = {{No 主観的健康感を中心とした在宅高齢者における 健康関連指標に関する共分散構造分析Title}},
volume = {45},
year = {2019}
}
@article{Gianfaldoni2017,
abstract = {For more than a century, radiotherapy has been an effective treatment for oncologic patients. The Authors report a brief history of the radiation therapy and its actual indication for the treatments of cutaneous malignant diseases.},
author = {Gianfaldoni, Serena and Gianfaldoni, Roberto and Wollina, Uwe and Lotti, Jacopo and Tchernev, Georgi and Lotti, Torello},
doi = {10.3889/oamjms.2017.122},
file = {:C\:/Users/febri/Desktop/Melanoma/paper/Gianfaldoni Gianfaldoni Dkk 2017.pdf:pdf},
issn = {18579655},
journal = {Open Access Macedonian Journal of Medical Sciences},
keywords = {Cancers,Cutaneous malignant diseases,Historical evolution,Radiotherapy,Therapeutic option},
number = {4 Special Issue GlobalDermatology},
pages = {521--525},
title = {{An Overview on Radiotherapy: From Its History to Its Current Applications in Dermatology}},
volume = {5},
year = {2017}
}
@article{Science2021,
author = {Science, Nonlinear and Phenomena, Complex},
doi = {10.1016/j.chaos.2021.110714},
file = {:C\:/Users/febri/Desktop/Melanoma/paper/10.1016@j.chaos.2021.110714.pdf:pdf},
issn = {0960-0779},
journal = {Chaos, Solitons and Fractals: the interdisciplinary journal of Nonlinear Science, and Nonequilibrium and Complex Phenomena},
keywords = {Biomedical signal processing,Decision support,Spik,biomedical signal processing},
pages = {110714},
publisher = {Elsevier Ltd},
title = {{Chaos , Solitons and Fractals Intelligent skin cancer detection applying autoencoder , MobileNetV2 and spiking neural networks Mesut To g}},
url = {https://doi.org/10.1016/j.chaos.2021.110714},
volume = {144},
year = {2021}
}
@inproceedings{Daghrir2020,
author = {Daghrir, J. and Tlig, L. and Bouchouicha, M. and Sayadi, M.},
booktitle = {5th International Conference on Advanced Technologies for Signal and Image Processing (ATSIP)},
doi = {10.1109/ATSIP49331.20},
pages = {1--5},
title = {{Melanoma skin cancer detection using deep learning and classical machine learning techniques: A hybrid approach}},
year = {2020}
}
@article{Sreelatha2019,
abstract = {The significance of pattern recognition techniques is widely enhanced in image processing and medical applications. Thus, lesion segmentation method is an essential technique of pattern recognition algorithms to detect the melanoma skin cancer in patients at earliest stage, otherwise, in further stages it becomes one of the deadliest disease and its mortality rate is very high. Therefore, a precise melanoma segmentation technique is introduced based on the Gradient and Feature Adaptive Contour (GFAC) model to detect melanoma skin cancer in earliest stage and diagnosis of dermoscopic images. In the proposed image segmentation technique pre-processing and noise elimination techniques are introduced to decrease noise and make execution faster. This technique helps in separating the required entity from the background and gather the information from the adjacent pixels of similar classes. Multiple Gaussian distributed patterns are adopted to extract efficient features and to get precise segmentation. The proposed GFACmodel is noise free and consist of smoother border. The segmentation model efficiency is tested on PH2 dataset. The superiority of the proposed modified gradient and feature adaptive contour model can be verified against various state-of-art-techniques in terms of segmented image, error reduction and efficient feature extraction.},
author = {Sreelatha, Tammineni and Subramanyam, M. V. and Prasad, M. N.Giri},
doi = {10.1007/s10916-019-1334-1},
file = {:C\:/Users/febri/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Sreelatha, Subramanyam, Prasad - 2019 - Early Detection of Skin Cancer Using Melanoma Segmentation technique.pdf:pdf},
issn = {1573689X},
journal = {Journal of Medical Systems},
keywords = {Feature extraction,Gradient,Melanoma,Segmentation},
number = {7},
pages = {1--7},
pmid = {31111236},
publisher = {Journal of Medical Systems},
title = {{Early Detection of Skin Cancer Using Melanoma Segmentation technique}},
volume = {43},
year = {2019}
}
@article{Tan2019,
author = {Tan, Teck Yan and Zhang, Li and Lim, Chee Peng},
doi = {10.1016/j.asoc.2019.105725},
file = {:C\:/Users/febri/Desktop/Melanoma/paper/tan2019.pdf:pdf},
issn = {1568-4946},
journal = {Applied Soft Computing Journal},
keywords = {skin cancer detection},
pages = {105725},
publisher = {Elsevier B.V.},
title = {{Intelligent skin cancer diagnosis using improved particle swarm optimization and deep learning models}},
url = {https://doi.org/10.1016/j.asoc.2019.105725},
volume = {84},
year = {2019}
}
@article{Vyshnevska2021,
abstract = {Our research generalized the essence of globalization, its impact on the world economy and society. The authors argue that each subject of the global space should have specific initial prerequisites and opportunities for adaptation to global changes, ensuring stable performance in the world scene. Negative global trends, as well as their impact on the environment, are determined. The study proves the expediency of using the adaptive approach in preserving various ecological systems of the world, environmental quality in parallel to leveling environmental risks and preserving natural and biological diversity in different regions of the world. The study outlines critical priorities in implementing the adaptive approach to minimize ecological threats because of their complexity and scale. The adaptive approach's essence is to adapt to the external environment, given the existing internal threats. The adaptive approach is more effective, as it does not impose tight restrictions and implies each state's ability to independently choose directions and priorities for further development, with due regard to both resource capabilities and national interests. The paper proves that implementation of the adaptive approach results in the effectiveness of measures aimed at serving the interests of the state and society, keeping in mind the depth and extent of problems, peculiarities, and pace of socio-economic development of any state as well as social consciousness concerning the existing ecological threats. The authors determined that crucial areas of adaptation for Ukraine include developing ecological networks, increased use of alternative energy sources, improvement of domestic waste management combined with environmental education and consciousness to each element of the environment. Adaptation efficiency critically depends on responsibility for the adoption, implementation, and effectiveness of the identified critical approaches at all government levels. Responsibility is a significant prerequisite and the basis for implementing the previously mentioned adaptive approach concerning the efficiency of environmental preservation measures, including commitments under the international agreement on climate action - the Paris Agreement.},
author = {Vyshnevska, O and Litvak, O and Melnyk, I and Oliinyk, T and Litvak, S},
doi = {10.15421/20},
file = {:C\:/Users/febri/Desktop/Melanoma/paper/UJE-21-23982.pdf:pdf},
journal = {Ukrainian Journal of Ecology},
keywords = {Adaptation,Adaptations,Alternative energy,Alternative energy sources,Biodiversity,Biology,Climate change,Consciousness,Domestic wastes,Economic development,Economics,Ecosystems,Energy resources,Environmental economics,Environmental education,Environmental impact,Environmental management,Environmental policy,Environmental protection,Environmental quality,Environmental risk,Freshwater resources,Global economy,Globalization,Integrated approach,International agreements,International organizations,Research,Social change,Society,Socioeconomic aspects,Threats,Trends,Waste management,World,World economy},
number = {1},
pages = {77--83},
title = {{Impact of globalization on the world environment}},
url = {https://ezp.lib.cam.ac.uk/login?url=https://www.proquest.com/scholarly-journals/impact-globalization-on-world-environment/docview/2503472261/se-2?accountid=9851%0Ahttps://libkey.io/libraries/603/openurl?genre=article&au=Vyshnevska%2C+O%3BLitvak%2C+O%3BMel},
volume = {11},
year = {2021}
}
@article{Du2018,
abstract = {As a key use of image processing, object detection has boomed along with the unprecedented advancement of Convolutional Neural Network (CNN) and its variants since 2012. When CNN series develops to Faster Region with CNN (R-CNN), the Mean Average Precision (mAP) has reached 76.4, whereas, the Frame Per Second (FPS) of Faster R-CNN remains 5 to 18 which is far slower than the real-time effect. Thus, the most urgent requirement of object detection improvement is to accelerate the speed. Based on the general introduction to the background and the core solution CNN, this paper exhibits one of the best CNN representatives You Only Look Once (YOLO), which breaks through the CNN family's tradition and innovates a complete new way of solving the object detection with most simple and high efficient way. Its fastest speed has achieved the exciting unparalleled result with FPS 155, and its mAP can also reach up to 78.6, both of which have surpassed the performance of Faster R-CNN greatly. Additionally, compared with the latest most advanced solution, YOLOv2 achieves an excellent tradeoff between speed and accuracy as well as an object detector with strong generalization ability to represent the whole image.},
author = {Du, Juan},
doi = {10.1088/1742-6596/1004/1/012029},
file = {:C\:/Users/febri/Desktop/Melanoma/paper/Du CNN YOLO 2018.pdf:pdf},
issn = {17426596},
journal = {Journal of Physics: Conference Series},
number = {1},
title = {{Understanding of Object Detection Based on CNN Family and YOLO}},
volume = {1004},
year = {2018}
}
@article{Senan2021,
abstract = {Melanoma is the most deadly type of skin cancer in humans. Which occurs as a result of a change in the pigment of the skin, which is known as pigment cells. Which produces a pigment known as melanin. Which appear in multiple colors. And asymmetry from one part to another. Its borders are irregular. And grow continuously. This disease can be treated and cured if there is an early diagnosis of the disease. Effective techniques are required for early detection using a Computer-Aided Diagnosis (CAD). In this paper ABCD rules have applied for automatic detecting skin cancer. In order to test the proposed system PH2 standard dataset has used, PH2 contains three types of skin diseases namely Atypical Nevi, Melanoma and Common Nevus. The propose system is divided into two stages: the first stage: pre-processing stage use to enhance the quality of image, the Gaussian filter method is employed to enhance the images and remove unwanted pixels. For extracting the Region of Interest (RoI) from dermoscopy images the contour method has been applied. Furthermore, Morphology method is considered for increasing the quality of skin lesions. The second stage: ABCD (Asymmetry, Border, Color and Diameter) rules have implemented to extract appropriate features. The obtaining features are processed by using Total Dermoscopic Score (TDS) for detection benign and malignant. Standard performance measures namely, Accuracy, Specificity and Sensitivity are used to calculate the results of proposed system. It is observed that the results of proposed system is satisfactory.},
author = {Senan, Ebrahim Mohammed and Jadhav, Mukti E},
doi = {10.1016/j.gltp.2021.01.001},
file = {:C\:/Users/febri/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Senan, Jadhav - 2021 - Analysis of dermoscopy images by using ABCD rule for early detection of skin cancer.pdf:pdf},
issn = {2666285X},
journal = {Global Transitions Proceedings},
month = {jun},
number = {1},
pages = {1--7},
publisher = {Elsevier BV},
title = {{Analysis of dermoscopy images by using ABCD rule for early detection of skin cancer}},
volume = {2},
year = {2021}
}
@article{Albahli2020,
author = {Albahli, Saleh and Nida, Nudrat and Irtaza, A U N and Yousaf, Muhammad Haroon and Member, Senior and Mahmood, Muhammad Tariq and Member, Senior},
doi = {10.1109/ACCESS.2020.3035345},
file = {:E\:/Skripsi/Previous Articles/Albahli Nida Dkk YOLOv4-DarkNet 2020.pdf:pdf},
pages = {198403--198414},
title = {{Melanoma Lesion Detection and Segmentation Using YOLOv4-DarkNet and Active Contour}},
volume = {8},
year = {2020}
}
@article{Arif2022a,
abstract = {One of the deadliest diseases is skin cancer, especially melanoma. The high resemblance between different skin lesions such as melanoma and nevus in the skin colour images increases the complexity of identification and diagnosis. An efficient automated early detection system for skin cancer detection is essential in order to save human lives, time, and effort. In this article, an automatic skin lesion classification system using a pretrained deep learning network and transfer learning was proposed. Here, diagnosing melanoma in premature stages, a detection system has been designed which contains the following digital image processing techniques. First, dermoscopy images of skin were taken and this is subjected to a preprocessing step for noise removal and postprocessing step for image enhancement. Then the processed image undergoes image segmentation using k-means and modified k-means clustering. Second, using feature extraction technology, Gray Level Co-occurrence Matrix, and first order statistics, characteristics are extracted. Features are selected on the basis of Harris Hawks optimization (HHO). Finally, various classifiers are used for predicting the stages and efficiency of the proposed work. Measures of well-known quantities, sensitivity, precision, accuracy, and specificity are used in assessing the efficiency of the suggested method, where higher values were obtained. Compared to the current methods, it is found that the classification rate exceeded the output of the current approaches in the performance of the proposed approach.},
author = {Arif, Muhammad and Philip, Felix M. and Ajesh, F. and Izdrui, Diana and Craciun, Maria Daniela and Geman, Oana},
doi = {10.1155/2022/6952304},
file = {:C\:/Users/febri/Desktop/Melanoma/paper/Arif Philip Dkk 2022.pdf:pdf},
issn = {2040-2295},
journal = {Journal of Healthcare Engineering},
pages = {1--15},
pmid = {35186235},
title = {{Automated Detection of Nonmelanoma Skin Cancer Based on Deep Convolutional Neural Network}},
volume = {2022},
year = {2022}
}
@article{Veneman2021,
author = {Veneman, Rowin},
file = {:C\:/Users/febri/Desktop/Melanoma/paper/Veneman 2021.pdf:pdf},
title = {{Real-time Skin Cancer Detection Using Neural Networks on an Embedded Device}},
year = {2021}
}
@article{Combalia2019,
abstract = {This article summarizes the BCN20000 dataset, composed of 19424 dermoscopic images of skin lesions captured from 2010 to 2016 in the facilities of the Hospital Cl\'inic in Barcelona. With this dataset, we aim to study the problem of unconstrained classification of dermoscopic images of skin cancer, including lesions found in hard-to-diagnose locations (nails and mucosa), large lesions which do not fit in the aperture of the dermoscopy device, and hypo-pigmented lesions. The BCN20000 will be provided to the participants of the ISIC Challenge 2019, where they will be asked to train algorithms to classify dermoscopic images of skin cancer automatically.},
archivePrefix = {arXiv},
arxivId = {1908.02288},
author = {Combalia, Marc and Codella, Noel C. F. and Rotemberg, Veronica and Helba, Brian and Vilaplana, Veronica and Reiter, Ofer and Carrera, Cristina and Barreiro, Alicia and Halpern, Allan C. and Puig, Susana and Malvehy, Josep},
eprint = {1908.02288},
file = {:E\:/Skripsi/Previous Articles//Combalia et al. - 2019 - BCN20000 Dermoscopic Lesions in the Wild.pdf:pdf},
pages = {3--5},
title = {{BCN20000: Dermoscopic Lesions in the Wild}},
url = {http://arxiv.org/abs/1908.02288},
year = {2019}
}
@article{Gavrilov2019,
abstract = {Skin cancer is the most common type of cancer [1]. Between different malignant skin pathology melanoma is the most fleeting and mortality. Despite the superficial location of pathologies, only half of patients seek medical assistance on the early stages[2]. Treatment on the early (epidermal) stage provides a significantly higher chance of recovery. To assist a wide range of people in the early skin cancer detection, a software package was developed. The software based on deep convolutional neural networks technology. This complex allows to classify normal and malignant pathology on the uploaded photos. In clinical practice doctors use the ABCDE symptom's complex. This complex characterizes the observation of pigment spot asymmetry, border irregularities, color unevenness, diameter, and evolution [3]. The machine learning approach involves the computer evaluating similar factors when processing multiple images of different skin formations. The paper presents an algorithm for classification of skin lesions into pathology and norm using convolutional neural network architecture Xception with prior images segmentation. The upper classifying layers were frozen and new ones were added to classify skin diseases in the pre-trained neural network Xception. As a result, the classification of benign and malignant skin tumors provided at least 89% accuracy. At the moment, the result of research work is designed in form of application software that allows to download the image of pigmented skin spots from the camera. It is available on http://skincheckup.online.},
author = {Gavrilov, Dmitriy and Lazarenko, Lyubov and Zakirov, Emil},
doi = {10.1109/IC-AIAI48757.2019.00017},
file = {:C\:/Users/febri/AppData/Local/Mendeley Ltd/Mendeley Desktop/Downloaded//Gavrilov, Lazarenko, Zakirov - 2019 - AI Recognition in Skin Pathologies Detection.pdf:pdf},
isbn = {9781728143262},
journal = {Proceedings - 2019 International Conference on Artificial Intelligence: Applications and Innovations, IC-AIAI 2019},
keywords = {CNN,Preventive care,artificial intelligence,medical information systems,neural networks,recommendation systems},
pages = {54--56},
publisher = {IEEE},
title = {{AI Recognition in Skin Pathologies Detection}},
year = {2019}
}
@article{Kasper-eulaers2021,
author = {Kasper-eulaers, Margrit and Hahn, Nico and Berger, Stian and Sebulonsen, Tom and Myrland, {\O}ystein},
file = {:C\:/Users/febri/Desktop/Melanoma/paper/algorithms-14-00114-v2.pdf:pdf},
keywords = {cnns,object detection,vehicle detection,yolov5},
title = {{Short Communication : Detecting Heavy Goods Vehicles in Rest Areas in Winter Conditions Using YOLOv5}},
year = {2021}
}
@book{Nie2019,
abstract = {"Conference Record Number: 47216; IEEE Catalog Number: CFP1903P-ART."},
author = {Nie, Yali; and Sommella, Paolo; and O'nils, Mattias; and Liguori, Consolatina; and Lundgren, Jan;},
file = {:C\:/Users/febri/Desktop/Melanoma/paper/Nie Sommella 2019.pdf:pdf},
isbn = {9781728126036},
title = {{Automatic Detection of Melanoma with Yolo Deep Convolutional Neural Networks}},
year = {2019}
}
@article{Alasadi2015,
author = {Alasadi, Abbas Hanon and Alsafy, Baidaa},
doi = {10.5815/ijitcs.2015.12.08},
file = {:C\:/Users/febri/AppData/Local/Mendeley Ltd/Mendeley Desktop/Downloaded//Alasadi, Alsafy - 2015 - Early Detection and Classification of Melanoma Skin Cancer.pdf:pdf},
journal = {I.J. Information Technology and Computer Science},
pages = {67--74},
title = {{Early Detection and Classification of Melanoma Skin Cancer}},
volume = {12},
year = {2015}
}
@article{Khamparia2021,
abstract = {As specified by World Health Organization, the occurrence of skin cancer has been growing over the past decades. At present, 2 to 3 million nonmelanoma skin cancers and 132 000 melanoma skin cancers arise worldwide annually. The detection and classification of skin cancer in early stage of development allow patients to have proper diagnosis and treatment. The goal of this article is to present a novel deep learning internet of health and things (IoHT) driven framework for skin lesion classification in skin images using the concept of transfer learning. In proposed framework, automatic features are extracted from images using different pretrained architectures like VGG19, Inception V3, ResNet50, and SqueezeNet, which are fed into fully connected layer of convolutional neural network for classification of skin benign and malignant cells using dense and max pooling operation. In addition, the proposed system is fully integrated with an IoHT framework and can be used remotely to assist medical specialists in the diagnosis and treatment of skin cancer. It has been observed that performance metric evaluation of proposed framework outperformed other pretrained architectures in term of precision, recall, and accuracy in detection and classification of skin cancer from skin lesion images.},
author = {Khamparia, Aditya and Singh, Prakash Kumar and Rani, Poonam and Samanta, Debabrata and Khanna, Ashish and Bhushan, Bharat},
doi = {10.1002/ett.3963},
file = {:C\:/Users/febri/Desktop/Melanoma/paper/Khamparia Singh Dkk 2020.pdf:pdf},
issn = {21613915},
journal = {Transactions on Emerging Telecommunications Technologies},
number = {7},
pages = {1--11},
title = {{An Internet of Health Things-Driven Deep Learning Framework for Detection and Classification of Skin Cancer using Transfer Learning}},
volume = {32},
year = {2021}
}
@article{Zhang2019,
author = {Zhang, Xiaofan and Lu, Haoming and Hao, Cong and Li, Jiachen and Cheng, Bowen and Li, Yuhong and Rupnow, Kyle and Xiong, Jinjun and Huang, Thomas and Shi, Honghui and Hwu, Wen-mei and Chen, Deming},
file = {:C\:/Users/febri/Desktop/Melanoma/paper/xiaofan-zhang skynet 2020.pdf:pdf},
title = {{S n : h -e m o d t e s}},
year = {2019}
}
@article{Lai2018,
abstract = {Epidermal cancers include keratinocyte cancer, melanocyte cancer, and Merkel cell carcinoma. These cancers account for the vast majority of new cancers diagnosed in Australia, North America, and Europe. Keratinocyte cancer is the most common epidermal cancer and accounts for 7 out of 8 new cancers diagnosed in Australia. Melanoma and Merkel cell carcinoma are less common than keratinocyte carcinoma but are more important causes of mortality in Australia. Keratinocyte cancer has also been demonstrated to be a marker of cancer-prone phenotype. Risk factors for epidermal cancer include intrinsic and environmental factors, in particular exposure to ultraviolet radiation and advanced age. Actinic keratosis has an approximate prevalence of 79% of men and 68% of women between 60 and 69 years of age, and has a low risk of malignant transformation into squamous cell carcinoma. Basal cell carcinoma is the most common malignancy in Caucasians worldwide, with the incidence increasing by 2% per year in Australia. Squamous cell carcinoma is the second most common epidermal cancer, with an incidence of approximately 1035 or 472 per 100,000 person-years in men and women, respectively. Primary risk factors for both basal cell carcinoma and squamous cell carcinoma include light skin color, UV radiation exposure, and chronic immunosuppression. Although the rate of melanoma is increasing, the mortality in Australia is reducing and is currently 9%. The overall incidence of melanoma in Australia is approximately 50 cases per 100,000 persons (62 for men and 40 for women). Keratinocyte carcinoma and melanoma are risk factors for developing further skin cancer and primary malignancy. This contribution reviews the incidence, prevalence, and risk factors associated with the development of epidermal cancer and premalignant epidermal neoplasia.},
author = {Lai, Vivien and Cranwell, William and Sinclair, Rodney},
doi = {10.1016/j.clindermatol.2017.10.008},
file = {:C\:/Users/febri/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Lai, Cranwell, Sinclair - 2018 - Epidemiology of skin cancer in the mature patient.pdf:pdf},
issn = {18791131},
journal = {Clinics in Dermatology},
number = {2},
pages = {167--176},
pmid = {29566921},
publisher = {Elsevier Inc.},
title = {{Epidemiology of Skin Cancer in The Mature Patient}},
url = {https://doi.org/10.1016/j.clindermatol.2017.10.008},
volume = {36},
year = {2018}
}
@article{Ashraf2020,
author = {Ashraf, Rehan and Afzal, Sitara and Rehman, Attiq U R and Gul, Sarah and Baber, Junaid and Bakhtyar, Maheen and Mehmood, Irfan and Song, Oh-young and Maqsood, Muazzam},
doi = {10.1109/ACCESS.2020.3014701},
file = {:C\:/Users/febri/Desktop/Melanoma/paper/10.1109@ACCESS.2020.3014701.pdf:pdf},
title = {{Region-of-Interest Based Transfer Learning Assisted Framework for Skin Cancer Detection}},
year = {2020}
}
@article{GuptaPola2021,
abstract = {Blood cell count plays a vital role within the field of clinical diagnosing. In the recent times," the deep-learning-based detection method YOLO" has been proved be a novel method to count the blood cells and platelets effectively. Albeit its efficiency, the YOLO detection method has a few limitations like insufficient positioning of the bounding boxes and in distinguishing overlapping objects, in order to overcome these limitations, we propose a brand new deep-learning-based method, termed Attention-YOLO. Attention-YOLO is achieved by adding the channel attention mechanism and the spatial attention mechanism to the feature extraction network. By using the filtered and weighted feature vector to switch the initial feature vector for residual fusion, Attention-YOLO can help the network to boost the detection accuracy. The experimental results suggest that the Attention-YOLO has a higher detection performance in somatic cell count without introducing too many additional parameters compared to YOLO network. The popularity accuracy of cells (RBCs, WBCs, and platelets) in Attention-YOLO has an improvement of 6.70%, 2.13%, and 10.44%, respectively, and in addition to that the mean Average Precision (mAP) demonstrated an improvement of 7.14%. The purpose of this paper is to compare the performance of YOLO v3, v4 and v5 and conclude which is the best suitable method.},
author = {{Gupta Pola}, Venkateswara and {Bhavya Vaishnavi}, Amrutham and {Suraj Karra}, Sai},
issn = {2395-0072},
journal = {International Research Journal of Engineering and Technology},
pages = {4225--4229},
title = {{Comparison of YOLOv3, YOLOv4 and YOLOv5 Performance for Detection of Blood Cells}},
year = {2021}
}
@article{Wan2021,
abstract = {Background: High-quality colonoscopy is essential to prevent the occurrence of colorectal cancers. The data of colonoscopy are mainly stored in the form of images. Therefore, artificial intelligence-assisted colonoscopy based on medical images is not only a research hotspot, but also one of the effective auxiliary means to improve the detection rate of adenomas. This research has become the focus of medical institutions and scientific research departments and has important clinical and scientific research value. Methods: In this paper, we propose a YOLOv5 model based on a self-attention mechanism for polyp target detection. This method uses the idea of regression, using the entire image as the input of the network and directly returning the target frame of this position in multiple positions of the image. In the feature extraction process, an attention mechanism is added to enhance the contribution of information-rich feature channels and weaken the interference of useless channels; Results: The experimental results show that the method can accurately identify polyp images, especially for the small polyps and the polyps with inconspicuous contrasts, and the detection speed is greatly improved compared with the comparison algorithm. Conclusions: This study will be of great help in reducing the missed diagnosis of clinicians during endoscopy and treatment, and it is also of great significance to the development of clinicians' clinical work.},
author = {Wan, Jingjing and Chen, Bolun and Yu, Yongtao},
doi = {10.3390/diagnostics11122264},
file = {:C\:/Users/febri/Desktop/Melanoma/paper/diagnostics-11-02264.pdf:pdf},
issn = {20754418},
journal = {Diagnostics},
keywords = {Attention mechanism,Colorectal cancer,Polyp detection,YOLOv5},
number = {12},
title = {{Polyp detection from colorectum images by using attentive YOLOv5}},
volume = {11},
year = {2021}
}
@article{Rahman2022,
author = {Rahman, Mahbubur and Nasir, Mostofa Kamal and Khan, Saikat Islam},
doi = {10.20944/preprints2},
file = {:C\:/Users/febri/Desktop/Melanoma/paper/preprints202201.0258.v1.pdf:pdf},
keywords = {and speed up robust,cnn,convolutional neural network,dient,fast bounding box,fbb,histogram-oriented gra-,hog,lbp,local binary pattern,machine learning,ml},
number = {January},
title = {{Hybrid Feature Fusion and Machine Learning Approaches for Melanoma Skin Cancer Detection}},
year = {2022}
}
